{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test learning rate finder and one cycle learning rate\n",
    "\n",
    "From fast.ai\n",
    "\n",
    "Test this implementation:\n",
    "\n",
    "https://github.com/titu1994/keras-one-cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/s/S.Rasp/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from cbrain.imports import *\n",
    "from cbrain.data_generator import *\n",
    "from cbrain.models import *\n",
    "from cbrain.utils import limit_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '/local/S.Rasp/preprocessed_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator will have 14057472 samples in 27456 batches\n",
      "Features have shape 94; targets have shape 65\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(\n",
    "    data_dir=DATADIR, \n",
    "    feature_fn='32_col_engy_ess_3d_train_shuffle_features.nc',\n",
    "    target_fn='32_col_engy_ess_3d_train_shuffle_targets.nc',\n",
    "    batch_size=512,\n",
    "    norm_fn='32_col_engy_ess_3d_train_norm.nc',\n",
    "    fsub='feature_means', \n",
    "    fdiv='feature_stds', \n",
    "    tmult='target_conv',\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fc_model(94, 65, [256]*9, 1e-3, 'mse', activation='LeakyReLU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 94)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               24320     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 65)                16705     \n",
      "=================================================================\n",
      "Total params: 567,361\n",
      "Trainable params: 567,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 5378/27456 [====>.........................] - ETA: 4:07 - loss: 0.0025 - rmse: 0.0376 - log_loss: -1.5400 - var_ratio: 0.6953 - mean_squared_error: 0.0025 - var_loss: 6.3088e-06"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-057462580a18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;31m# This actually returns the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_gen.return_generator(),   # This actually returns the generator\n",
    "    train_gen.n_batches,\n",
    "    epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now use Learning rate finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clr import LRFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s/S.Rasp/miniconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:55: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    }
   ],
   "source": [
    "model = fc_model(94, 65, [256]*9, 1e-3, 'mse', activation='LeakyReLU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27456"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen.n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_callback = LRFinder(train_gen.n_batches * 10, train_gen.batch_size,\n",
    "                       1e-5, 1e-3, stopping_criterion_factor=50,\n",
    "                       # validation_data=(X_val, Y_val),\n",
    "                       lr_scale='exp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s/S.Rasp/miniconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:55: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "   1/1000 [..............................] - ETA: 6:22 - loss: 0.0108 - rmse: 0.0940 - log_loss: -1.0681 - var_ratio: 0.3621 - mean_squared_error: 0.0108 - var_loss: 2.5224e-05 - LRFinder: lr = 0.00001009 \n",
      "   2/1000 [..............................] - ETA: 3:45 - loss: 0.0109 - rmse: 0.0949 - log_loss: -1.0608 - var_ratio: 0.3792 - mean_squared_error: 0.0109 - var_loss: 2.3856e-05 - LRFinder: lr = 0.00001017 \n",
      " - LRFinder: lr = 0.00001026 \n",
      " - LRFinder: lr = 0.00001035 \n",
      " - LRFinder: lr = 0.00001044 \n",
      " - LRFinder: lr = 0.00001053 \n",
      " - LRFinder: lr = 0.00001062 \n",
      "   8/1000 [..............................] - ETA: 1:02 - loss: 0.0106 - rmse: 0.0926 - log_loss: -1.0736 - var_ratio: 0.3314 - mean_squared_error: 0.0106 - var_loss: 2.8646e-05 - LRFinder: lr = 0.00001071 \n",
      " - LRFinder: lr = 0.00001081 \n",
      " - LRFinder: lr = 0.00001090 \n",
      " - LRFinder: lr = 0.00001099 \n",
      " - LRFinder: lr = 0.00001109 \n",
      " - LRFinder: lr = 0.00001118 \n",
      "  14/1000 [..............................] - ETA: 39s - loss: 0.0103 - rmse: 0.0906 - log_loss: -1.0858 - var_ratio: 0.2934 - mean_squared_error: 0.0103 - var_loss: 3.2819e-05  - LRFinder: lr = 0.00001128 \n",
      " - LRFinder: lr = 0.00001138 \n",
      " - LRFinder: lr = 0.00001148 \n",
      " - LRFinder: lr = 0.00001158 \n",
      " - LRFinder: lr = 0.00001168 \n",
      "  19/1000 [..............................] - ETA: 31s - loss: 0.0099 - rmse: 0.0889 - log_loss: -1.0952 - var_ratio: 0.2709 - mean_squared_error: 0.0099 - var_loss: 3.4829e-05 - LRFinder: lr = 0.00001178 \n",
      " - LRFinder: lr = 0.00001188 \n",
      " - LRFinder: lr = 0.00001198 \n",
      " - LRFinder: lr = 0.00001208 \n",
      " - LRFinder: lr = 0.00001219 \n",
      " - LRFinder: lr = 0.00001229 \n",
      "  25/1000 [..............................] - ETA: 25s - loss: 0.0097 - rmse: 0.0873 - log_loss: -1.1048 - var_ratio: 0.2513 - mean_squared_error: 0.0097 - var_loss: 3.7012e-05 - LRFinder: lr = 0.00001240 \n",
      " - LRFinder: lr = 0.00001251 \n",
      " - LRFinder: lr = 0.00001262 \n",
      " - LRFinder: lr = 0.00001273 \n",
      " - LRFinder: lr = 0.00001284 \n",
      "  30/1000 [..............................] - ETA: 23s - loss: 0.0094 - rmse: 0.0858 - log_loss: -1.1140 - var_ratio: 0.2366 - mean_squared_error: 0.0094 - var_loss: 3.8035e-05 - LRFinder: lr = 0.00001295 \n",
      " - LRFinder: lr = 0.00001306 \n",
      " - LRFinder: lr = 0.00001317 \n",
      " - LRFinder: lr = 0.00001329 \n",
      " - LRFinder: lr = 0.00001340 \n",
      " - LRFinder: lr = 0.00001352 \n",
      "  36/1000 [>.............................] - ETA: 20s - loss: 0.0091 - rmse: 0.0841 - log_loss: -1.1248 - var_ratio: 0.2225 - mean_squared_error: 0.0091 - var_loss: 3.8727e-05 - LRFinder: lr = 0.00001363 \n",
      " - LRFinder: lr = 0.00001375 \n",
      " - LRFinder: lr = 0.00001387 \n",
      " - LRFinder: lr = 0.00001399 \n",
      " - LRFinder: lr = 0.00001411 \n",
      "  41/1000 [>.............................] - ETA: 19s - loss: 0.0089 - rmse: 0.0830 - log_loss: -1.1315 - var_ratio: 0.2134 - mean_squared_error: 0.0089 - var_loss: 3.9659e-05 - LRFinder: lr = 0.00001423 \n",
      " - LRFinder: lr = 0.00001436 \n",
      " - LRFinder: lr = 0.00001448 \n",
      " - LRFinder: lr = 0.00001460 \n",
      " - LRFinder: lr = 0.00001473 \n",
      "  46/1000 [>.............................] - ETA: 18s - loss: 0.0088 - rmse: 0.0821 - log_loss: -1.1378 - var_ratio: 0.2050 - mean_squared_error: 0.0088 - var_loss: 4.0929e-05 - LRFinder: lr = 0.00001486 \n",
      " - LRFinder: lr = 0.00001499 \n",
      " - LRFinder: lr = 0.00001512 \n",
      " - LRFinder: lr = 0.00001525 \n",
      " - LRFinder: lr = 0.00001538 \n",
      "  51/1000 [>.............................] - ETA: 17s - loss: 0.0087 - rmse: 0.0813 - log_loss: -1.1437 - var_ratio: 0.1988 - mean_squared_error: 0.0087 - var_loss: 4.1620e-05 - LRFinder: lr = 0.00001551 \n",
      " - LRFinder: lr = 0.00001565 \n",
      " - LRFinder: lr = 0.00001578 \n",
      " - LRFinder: lr = 0.00001592 \n",
      "  55/1000 [>.............................] - ETA: 17s - loss: 0.0085 - rmse: 0.0805 - log_loss: -1.1490 - var_ratio: 0.1953 - mean_squared_error: 0.0085 - var_loss: 4.1875e-05 - LRFinder: lr = 0.00001605 \n",
      " - LRFinder: lr = 0.00001619 \n",
      " - LRFinder: lr = 0.00001633 \n",
      " - LRFinder: lr = 0.00001647 \n",
      "  59/1000 [>.............................] - ETA: 17s - loss: 0.0084 - rmse: 0.0798 - log_loss: -1.1539 - var_ratio: 0.1930 - mean_squared_error: 0.0084 - var_loss: 4.2007e-05 - LRFinder: lr = 0.00001662 \n",
      " - LRFinder: lr = 0.00001676 \n",
      " - LRFinder: lr = 0.00001691 \n",
      " - LRFinder: lr = 0.00001705 \n",
      " - LRFinder: lr = 0.00001720 \n",
      "  64/1000 [>.............................] - ETA: 16s - loss: 0.0083 - rmse: 0.0789 - log_loss: -1.1596 - var_ratio: 0.1921 - mean_squared_error: 0.0083 - var_loss: 4.1755e-05 - LRFinder: lr = 0.00001735 \n",
      " - LRFinder: lr = 0.00001750 \n",
      " - LRFinder: lr = 0.00001765 \n",
      " - LRFinder: lr = 0.00001780 \n",
      " - LRFinder: lr = 0.00001796 \n",
      "  69/1000 [=>............................] - ETA: 16s - loss: 0.0081 - rmse: 0.0781 - log_loss: -1.1653 - var_ratio: 0.1909 - mean_squared_error: 0.0081 - var_loss: 4.1698e-05 - LRFinder: lr = 0.00001811 \n",
      " - LRFinder: lr = 0.00001827 \n",
      " - LRFinder: lr = 0.00001843 \n",
      " - LRFinder: lr = 0.00001858 \n",
      "  73/1000 [=>............................] - ETA: 15s - loss: 0.0081 - rmse: 0.0775 - log_loss: -1.1692 - var_ratio: 0.1906 - mean_squared_error: 0.0081 - var_loss: 4.1877e-05 - LRFinder: lr = 0.00001875 \n",
      " - LRFinder: lr = 0.00001891 \n",
      " - LRFinder: lr = 0.00001907 \n",
      " - LRFinder: lr = 0.00001924 \n",
      " - LRFinder: lr = 0.00001940 \n",
      "  78/1000 [=>............................] - ETA: 15s - loss: 0.0080 - rmse: 0.0769 - log_loss: -1.1733 - var_ratio: 0.1918 - mean_squared_error: 0.0080 - var_loss: 4.1872e-05 - LRFinder: lr = 0.00001957 \n",
      " - LRFinder: lr = 0.00001974 \n",
      " - LRFinder: lr = 0.00001991 \n",
      " - LRFinder: lr = 0.00002008 \n",
      " - LRFinder: lr = 0.00002026 \n",
      "  83/1000 [=>............................] - ETA: 14s - loss: 0.0079 - rmse: 0.0764 - log_loss: -1.1773 - var_ratio: 0.1939 - mean_squared_error: 0.0079 - var_loss: 4.1727e-05 - LRFinder: lr = 0.00002043 \n",
      " - LRFinder: lr = 0.00002061 \n",
      " - LRFinder: lr = 0.00002079 \n",
      " - LRFinder: lr = 0.00002097 \n",
      "  87/1000 [=>............................] - ETA: 14s - loss: 0.0078 - rmse: 0.0758 - log_loss: -1.1812 - var_ratio: 0.1959 - mean_squared_error: 0.0078 - var_loss: 4.1389e-05 - LRFinder: lr = 0.00002115 \n",
      " - LRFinder: lr = 0.00002133 \n",
      " - LRFinder: lr = 0.00002151 \n",
      " - LRFinder: lr = 0.00002170 \n",
      "  91/1000 [=>............................] - ETA: 14s - loss: 0.0077 - rmse: 0.0753 - log_loss: -1.1849 - var_ratio: 0.1972 - mean_squared_error: 0.0077 - var_loss: 4.1432e-05 - LRFinder: lr = 0.00002189 \n",
      " - LRFinder: lr = 0.00002208 \n",
      " - LRFinder: lr = 0.00002227 \n",
      " - LRFinder: lr = 0.00002246 \n",
      "  95/1000 [=>............................] - ETA: 14s - loss: 0.0076 - rmse: 0.0748 - log_loss: -1.1882 - var_ratio: 0.1997 - mean_squared_error: 0.0076 - var_loss: 4.1259e-05 - LRFinder: lr = 0.00002265 \n",
      " - LRFinder: lr = 0.00002285 \n",
      " - LRFinder: lr = 0.00002305 \n",
      " - LRFinder: lr = 0.00002325 \n",
      " - LRFinder: lr = 0.00002345 \n",
      " 100/1000 [==>...........................] - ETA: 14s - loss: 0.0075 - rmse: 0.0742 - log_loss: -1.1929 - var_ratio: 0.2037 - mean_squared_error: 0.0075 - var_loss: 4.0640e-05 - LRFinder: lr = 0.00002365 \n",
      " - LRFinder: lr = 0.00002385 \n",
      " - LRFinder: lr = 0.00002406 \n",
      " - LRFinder: lr = 0.00002427 \n",
      " - LRFinder: lr = 0.00002448 \n",
      " 105/1000 [==>...........................] - ETA: 13s - loss: 0.0074 - rmse: 0.0736 - log_loss: -1.1969 - var_ratio: 0.2075 - mean_squared_error: 0.0074 - var_loss: 4.0363e-05 - LRFinder: lr = 0.00002469 \n",
      " - LRFinder: lr = 0.00002490 \n",
      " - LRFinder: lr = 0.00002512 \n",
      " - LRFinder: lr = 0.00002534 \n",
      " - LRFinder: lr = 0.00002556 \n",
      " 110/1000 [==>...........................] - ETA: 13s - loss: 0.0073 - rmse: 0.0731 - log_loss: -1.2009 - var_ratio: 0.2120 - mean_squared_error: 0.0073 - var_loss: 3.9949e-05 - LRFinder: lr = 0.00002578 \n",
      " - LRFinder: lr = 0.00002600 \n",
      " - LRFinder: lr = 0.00002622 \n",
      " - LRFinder: lr = 0.00002645 \n",
      " - LRFinder: lr = 0.00002668 \n",
      " 115/1000 [==>...........................] - ETA: 13s - loss: 0.0072 - rmse: 0.0726 - log_loss: -1.2045 - var_ratio: 0.2166 - mean_squared_error: 0.0072 - var_loss: 3.9648e-05 - LRFinder: lr = 0.00002691 \n",
      " - LRFinder: lr = 0.00002714 \n",
      " - LRFinder: lr = 0.00002738 \n",
      " - LRFinder: lr = 0.00002761 \n",
      " - LRFinder: lr = 0.00002785 \n",
      " 120/1000 [==>...........................] - ETA: 13s - loss: 0.0071 - rmse: 0.0720 - log_loss: -1.2083 - var_ratio: 0.2226 - mean_squared_error: 0.0071 - var_loss: 3.9036e-05 - LRFinder: lr = 0.00002809 \n",
      " - LRFinder: lr = 0.00002834 \n",
      " - LRFinder: lr = 0.00002858 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - LRFinder: lr = 0.00002883 \n",
      " - LRFinder: lr = 0.00002908 \n",
      " 125/1000 [==>...........................] - ETA: 13s - loss: 0.0071 - rmse: 0.0715 - log_loss: -1.2119 - var_ratio: 0.2286 - mean_squared_error: 0.0071 - var_loss: 3.8495e-05 - LRFinder: lr = 0.00002933 \n",
      " - LRFinder: lr = 0.00002958 \n",
      " - LRFinder: lr = 0.00002984 \n",
      " - LRFinder: lr = 0.00003010 \n",
      " - LRFinder: lr = 0.00003036 \n",
      " 130/1000 [==>...........................] - ETA: 12s - loss: 0.0070 - rmse: 0.0710 - log_loss: -1.2157 - var_ratio: 0.2337 - mean_squared_error: 0.0070 - var_loss: 3.8160e-05 - LRFinder: lr = 0.00003062 \n",
      " - LRFinder: lr = 0.00003088 \n",
      " - LRFinder: lr = 0.00003115 \n",
      " - LRFinder: lr = 0.00003142 \n",
      " - LRFinder: lr = 0.00003169 \n",
      " 135/1000 [===>..........................] - ETA: 12s - loss: 0.0069 - rmse: 0.0705 - log_loss: -1.2195 - var_ratio: 0.2399 - mean_squared_error: 0.0069 - var_loss: 3.7619e-05 - LRFinder: lr = 0.00003196 \n",
      " - LRFinder: lr = 0.00003224 \n",
      " - LRFinder: lr = 0.00003252 \n",
      " - LRFinder: lr = 0.00003280 \n",
      " - LRFinder: lr = 0.00003308 \n",
      " - LRFinder: lr = 0.00003337 \n",
      " 141/1000 [===>..........................] - ETA: 12s - loss: 0.0068 - rmse: 0.0699 - log_loss: -1.2238 - var_ratio: 0.2476 - mean_squared_error: 0.0068 - var_loss: 3.6951e-05 - LRFinder: lr = 0.00003366 \n",
      " - LRFinder: lr = 0.00003395 \n",
      " - LRFinder: lr = 0.00003424 \n",
      " - LRFinder: lr = 0.00003454 \n",
      " - LRFinder: lr = 0.00003484 \n",
      " - LRFinder: lr = 0.00003514 \n",
      " 147/1000 [===>..........................] - ETA: 12s - loss: 0.0067 - rmse: 0.0693 - log_loss: -1.2285 - var_ratio: 0.2551 - mean_squared_error: 0.0067 - var_loss: 3.6280e-05 - LRFinder: lr = 0.00003544 \n",
      " - LRFinder: lr = 0.00003575 \n",
      " - LRFinder: lr = 0.00003606 \n",
      " - LRFinder: lr = 0.00003637 \n",
      " - LRFinder: lr = 0.00003668 \n",
      " - LRFinder: lr = 0.00003700 \n",
      " 153/1000 [===>..........................] - ETA: 11s - loss: 0.0066 - rmse: 0.0686 - log_loss: -1.2333 - var_ratio: 0.2632 - mean_squared_error: 0.0066 - var_loss: 3.5555e-05 - LRFinder: lr = 0.00003732 \n",
      " - LRFinder: lr = 0.00003764 \n",
      " - LRFinder: lr = 0.00003797 \n",
      " - LRFinder: lr = 0.00003830 \n",
      " - LRFinder: lr = 0.00003863 \n",
      " 158/1000 [===>..........................] - ETA: 11s - loss: 0.0065 - rmse: 0.0681 - log_loss: -1.2373 - var_ratio: 0.2707 - mean_squared_error: 0.0065 - var_loss: 3.4905e-05 - LRFinder: lr = 0.00003896 \n",
      " - LRFinder: lr = 0.00003930 \n",
      " - LRFinder: lr = 0.00003964 \n",
      " - LRFinder: lr = 0.00003998 \n",
      " - LRFinder: lr = 0.00004033 \n",
      " 163/1000 [===>..........................] - ETA: 11s - loss: 0.0064 - rmse: 0.0676 - log_loss: -1.2413 - var_ratio: 0.2776 - mean_squared_error: 0.0064 - var_loss: 3.4341e-05 - LRFinder: lr = 0.00004068 \n",
      " - LRFinder: lr = 0.00004103 \n",
      " - LRFinder: lr = 0.00004138 \n",
      " - LRFinder: lr = 0.00004174 \n",
      " - LRFinder: lr = 0.00004210 \n",
      " 168/1000 [====>.........................] - ETA: 11s - loss: 0.0063 - rmse: 0.0671 - log_loss: -1.2455 - var_ratio: 0.2850 - mean_squared_error: 0.0063 - var_loss: 3.3742e-05 - LRFinder: lr = 0.00004247 \n",
      " - LRFinder: lr = 0.00004283 \n",
      " - LRFinder: lr = 0.00004320 \n",
      " - LRFinder: lr = 0.00004358 \n",
      " - LRFinder: lr = 0.00004395 \n",
      " 173/1000 [====>.........................] - ETA: 11s - loss: 0.0063 - rmse: 0.0666 - log_loss: -1.2495 - var_ratio: 0.2924 - mean_squared_error: 0.0063 - var_loss: 3.3169e-05 - LRFinder: lr = 0.00004433 \n",
      " - LRFinder: lr = 0.00004472 \n",
      " - LRFinder: lr = 0.00004510 \n",
      " - LRFinder: lr = 0.00004549 \n",
      " - LRFinder: lr = 0.00004589 \n",
      " 178/1000 [====>.........................] - ETA: 11s - loss: 0.0062 - rmse: 0.0661 - log_loss: -1.2535 - var_ratio: 0.2992 - mean_squared_error: 0.0062 - var_loss: 3.2664e-05 - LRFinder: lr = 0.00004628 \n",
      " - LRFinder: lr = 0.00004668 \n",
      " - LRFinder: lr = 0.00004709 \n",
      " - LRFinder: lr = 0.00004749 \n",
      " - LRFinder: lr = 0.00004790 \n",
      " 183/1000 [====>.........................] - ETA: 11s - loss: 0.0061 - rmse: 0.0656 - log_loss: -1.2574 - var_ratio: 0.3059 - mean_squared_error: 0.0061 - var_loss: 3.2153e-05 - LRFinder: lr = 0.00004832 \n",
      " - LRFinder: lr = 0.00004874 \n",
      " - LRFinder: lr = 0.00004916 \n",
      " - LRFinder: lr = 0.00004958 \n",
      " - LRFinder: lr = 0.00005001 \n",
      " 188/1000 [====>.........................] - ETA: 10s - loss: 0.0061 - rmse: 0.0651 - log_loss: -1.2613 - var_ratio: 0.3138 - mean_squared_error: 0.0061 - var_loss: 3.1572e-05 - LRFinder: lr = 0.00005044 \n",
      " - LRFinder: lr = 0.00005088 \n",
      " - LRFinder: lr = 0.00005132 \n",
      " - LRFinder: lr = 0.00005176 \n",
      " - LRFinder: lr = 0.00005221 \n",
      " 193/1000 [====>.........................] - ETA: 10s - loss: 0.0060 - rmse: 0.0646 - log_loss: -1.2656 - var_ratio: 0.3209 - mean_squared_error: 0.0060 - var_loss: 3.1049e-05 - LRFinder: lr = 0.00005266 \n",
      " - LRFinder: lr = 0.00005312 \n",
      " - LRFinder: lr = 0.00005358 \n",
      " - LRFinder: lr = 0.00005404 \n",
      " - LRFinder: lr = 0.00005451 \n",
      " 198/1000 [====>.........................] - ETA: 10s - loss: 0.0059 - rmse: 0.0642 - log_loss: -1.2694 - var_ratio: 0.3279 - mean_squared_error: 0.0059 - var_loss: 3.0523e-05 - LRFinder: lr = 0.00005498 \n",
      " - LRFinder: lr = 0.00005545 \n",
      " - LRFinder: lr = 0.00005593 \n",
      " - LRFinder: lr = 0.00005642 \n",
      " - LRFinder: lr = 0.00005690 \n",
      " 203/1000 [=====>........................] - ETA: 10s - loss: 0.0059 - rmse: 0.0637 - log_loss: -1.2734 - var_ratio: 0.3345 - mean_squared_error: 0.0059 - var_loss: 3.0037e-05 - LRFinder: lr = 0.00005740 \n",
      " - LRFinder: lr = 0.00005789 \n",
      " - LRFinder: lr = 0.00005839 \n",
      " - LRFinder: lr = 0.00005890 \n",
      " - LRFinder: lr = 0.00005941 \n",
      " 208/1000 [=====>........................] - ETA: 10s - loss: 0.0058 - rmse: 0.0633 - log_loss: -1.2770 - var_ratio: 0.3413 - mean_squared_error: 0.0058 - var_loss: 2.9547e-05 - LRFinder: lr = 0.00005992 \n",
      " - LRFinder: lr = 0.00006044 \n",
      " - LRFinder: lr = 0.00006096 \n",
      " - LRFinder: lr = 0.00006149 \n",
      " - LRFinder: lr = 0.00006202 \n",
      " 213/1000 [=====>........................] - ETA: 10s - loss: 0.0057 - rmse: 0.0629 - log_loss: -1.2805 - var_ratio: 0.3474 - mean_squared_error: 0.0057 - var_loss: 2.9112e-05 - LRFinder: lr = 0.00006255 \n",
      " - LRFinder: lr = 0.00006310 \n",
      " - LRFinder: lr = 0.00006364 \n",
      " - LRFinder: lr = 0.00006419 \n",
      " - LRFinder: lr = 0.00006475 \n",
      " 218/1000 [=====>........................] - ETA: 10s - loss: 0.0057 - rmse: 0.0625 - log_loss: -1.2842 - var_ratio: 0.3536 - mean_squared_error: 0.0057 - var_loss: 2.8659e-05 - LRFinder: lr = 0.00006531 \n",
      " - LRFinder: lr = 0.00006587 \n",
      " - LRFinder: lr = 0.00006644 \n",
      " - LRFinder: lr = 0.00006701 \n",
      " - LRFinder: lr = 0.00006759 \n",
      " - LRFinder: lr = 0.00006818 \n",
      " 224/1000 [=====>........................] - ETA: 10s - loss: 0.0056 - rmse: 0.0620 - log_loss: -1.2885 - var_ratio: 0.3608 - mean_squared_error: 0.0056 - var_loss: 2.8126e-05 - LRFinder: lr = 0.00006877 \n",
      " - LRFinder: lr = 0.00006936 \n",
      " - LRFinder: lr = 0.00006996 \n",
      " - LRFinder: lr = 0.00007057 \n",
      " - LRFinder: lr = 0.00007118 \n",
      " 229/1000 [=====>........................] - ETA: 10s - loss: 0.0056 - rmse: 0.0616 - log_loss: -1.2916 - var_ratio: 0.3659 - mean_squared_error: 0.0056 - var_loss: 2.7773e-05 - LRFinder: lr = 0.00007179 \n",
      " - LRFinder: lr = 0.00007241 \n",
      " - LRFinder: lr = 0.00007304 \n",
      " - LRFinder: lr = 0.00007367 \n",
      " - LRFinder: lr = 0.00007431 \n",
      " - LRFinder: lr = 0.00007495 \n",
      " 235/1000 [======>.......................] - ETA: 9s - loss: 0.0055 - rmse: 0.0612 - log_loss: -1.2956 - var_ratio: 0.3731 - mean_squared_error: 0.0055 - var_loss: 2.7246e-05  - LRFinder: lr = 0.00007560 \n",
      " - LRFinder: lr = 0.00007625 \n",
      " - LRFinder: lr = 0.00007691 \n",
      " - LRFinder: lr = 0.00007757 \n",
      " - LRFinder: lr = 0.00007825 \n",
      " 240/1000 [======>.......................] - ETA: 9s - loss: 0.0055 - rmse: 0.0608 - log_loss: -1.2986 - var_ratio: 0.3779 - mean_squared_error: 0.0055 - var_loss: 2.6907e-05 - LRFinder: lr = 0.00007892 \n",
      " - LRFinder: lr = 0.00007960 \n",
      " - LRFinder: lr = 0.00008029 \n",
      " - LRFinder: lr = 0.00008099 \n",
      " - LRFinder: lr = 0.00008169 \n",
      " 245/1000 [======>.......................] - ETA: 9s - loss: 0.0054 - rmse: 0.0605 - log_loss: -1.3017 - var_ratio: 0.3825 - mean_squared_error: 0.0054 - var_loss: 2.6575e-05 - LRFinder: lr = 0.00008239 \n",
      " - LRFinder: lr = 0.00008310 \n",
      " - LRFinder: lr = 0.00008382 \n",
      " - LRFinder: lr = 0.00008455 \n",
      " - LRFinder: lr = 0.00008528 \n",
      " 250/1000 [======>.......................] - ETA: 9s - loss: 0.0054 - rmse: 0.0601 - log_loss: -1.3049 - var_ratio: 0.3878 - mean_squared_error: 0.0054 - var_loss: 2.6202e-05 - LRFinder: lr = 0.00008602 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - LRFinder: lr = 0.00008676 \n",
      " - LRFinder: lr = 0.00008751 \n",
      " - LRFinder: lr = 0.00008827 \n",
      " - LRFinder: lr = 0.00008903 \n",
      " 255/1000 [======>.......................] - ETA: 9s - loss: 0.0053 - rmse: 0.0598 - log_loss: -1.3082 - var_ratio: 0.3926 - mean_squared_error: 0.0053 - var_loss: 2.5851e-05 - LRFinder: lr = 0.00008980 \n",
      " - LRFinder: lr = 0.00009058 \n",
      " - LRFinder: lr = 0.00009136 \n",
      " - LRFinder: lr = 0.00009215 \n",
      " - LRFinder: lr = 0.00009294 \n",
      " - LRFinder: lr = 0.00009375 \n",
      " 261/1000 [======>.......................] - ETA: 9s - loss: 0.0053 - rmse: 0.0594 - log_loss: -1.3117 - var_ratio: 0.3980 - mean_squared_error: 0.0053 - var_loss: 2.5476e-05 - LRFinder: lr = 0.00009456 \n",
      " - LRFinder: lr = 0.00009538 \n",
      " - LRFinder: lr = 0.00009620 \n",
      " - LRFinder: lr = 0.00009703 \n",
      " - LRFinder: lr = 0.00009787 \n",
      " - LRFinder: lr = 0.00009872 \n",
      " 267/1000 [=======>......................] - ETA: 9s - loss: 0.0052 - rmse: 0.0591 - log_loss: -1.3150 - var_ratio: 0.4027 - mean_squared_error: 0.0052 - var_loss: 2.5145e-05 - LRFinder: lr = 0.00009957 \n",
      " - LRFinder: lr = 0.00010043 \n",
      " - LRFinder: lr = 0.00010130 \n",
      " - LRFinder: lr = 0.00010218 \n",
      " - LRFinder: lr = 0.00010306 \n",
      " 272/1000 [=======>......................] - ETA: 9s - loss: 0.0052 - rmse: 0.0588 - log_loss: -1.3177 - var_ratio: 0.4068 - mean_squared_error: 0.0052 - var_loss: 2.4835e-05 - LRFinder: lr = 0.00010395 \n",
      " - LRFinder: lr = 0.00010485 \n",
      " - LRFinder: lr = 0.00010575 \n",
      " - LRFinder: lr = 0.00010667 \n",
      " - LRFinder: lr = 0.00010759 \n",
      " 277/1000 [=======>......................] - ETA: 9s - loss: 0.0052 - rmse: 0.0585 - log_loss: -1.3203 - var_ratio: 0.4105 - mean_squared_error: 0.0052 - var_loss: 2.4614e-05 - LRFinder: lr = 0.00010852 \n",
      " - LRFinder: lr = 0.00010946 \n",
      " - LRFinder: lr = 0.00011041 \n",
      " - LRFinder: lr = 0.00011136 \n",
      " - LRFinder: lr = 0.00011232 \n",
      " 282/1000 [=======>......................] - ETA: 9s - loss: 0.0051 - rmse: 0.0582 - log_loss: -1.3228 - var_ratio: 0.4146 - mean_squared_error: 0.0051 - var_loss: 2.4330e-05 - LRFinder: lr = 0.00011329 \n",
      " - LRFinder: lr = 0.00011427 \n",
      " - LRFinder: lr = 0.00011526 \n",
      " - LRFinder: lr = 0.00011626 \n",
      " - LRFinder: lr = 0.00011726 \n",
      " 287/1000 [=======>......................] - ETA: 8s - loss: 0.0051 - rmse: 0.0580 - log_loss: -1.3253 - var_ratio: 0.4180 - mean_squared_error: 0.0051 - var_loss: 2.4101e-05 - LRFinder: lr = 0.00011828 \n",
      " - LRFinder: lr = 0.00011930 \n",
      " - LRFinder: lr = 0.00012033 \n",
      " - LRFinder: lr = 0.00012137 \n",
      " - LRFinder: lr = 0.00012242 \n",
      " 292/1000 [=======>......................] - ETA: 8s - loss: 0.0051 - rmse: 0.0577 - log_loss: -1.3276 - var_ratio: 0.4216 - mean_squared_error: 0.0051 - var_loss: 2.3879e-05 - LRFinder: lr = 0.00012348 \n",
      " - LRFinder: lr = 0.00012455 \n",
      " - LRFinder: lr = 0.00012562 \n",
      " - LRFinder: lr = 0.00012671 \n",
      " - LRFinder: lr = 0.00012780 \n",
      " 297/1000 [=======>......................] - ETA: 8s - loss: 0.0050 - rmse: 0.0575 - log_loss: -1.3299 - var_ratio: 0.4252 - mean_squared_error: 0.0050 - var_loss: 2.3635e-05 - LRFinder: lr = 0.00012891 \n",
      " - LRFinder: lr = 0.00013002 \n",
      " - LRFinder: lr = 0.00013115 \n",
      " - LRFinder: lr = 0.00013228 \n",
      " - LRFinder: lr = 0.00013342 \n",
      " 302/1000 [========>.....................] - ETA: 8s - loss: 0.0050 - rmse: 0.0572 - log_loss: -1.3322 - var_ratio: 0.4284 - mean_squared_error: 0.0050 - var_loss: 2.3394e-05 - LRFinder: lr = 0.00013458 \n",
      " - LRFinder: lr = 0.00013574 \n",
      " - LRFinder: lr = 0.00013691 \n",
      " - LRFinder: lr = 0.00013810 \n",
      " - LRFinder: lr = 0.00013929 \n",
      " 307/1000 [========>.....................] - ETA: 8s - loss: 0.0050 - rmse: 0.0570 - log_loss: -1.3344 - var_ratio: 0.4321 - mean_squared_error: 0.0050 - var_loss: 2.3142e-05 - LRFinder: lr = 0.00014050 \n",
      " - LRFinder: lr = 0.00014171 \n",
      " - LRFinder: lr = 0.00014294 \n",
      " - LRFinder: lr = 0.00014417 \n",
      " - LRFinder: lr = 0.00014542 \n",
      " 312/1000 [========>.....................] - ETA: 8s - loss: 0.0049 - rmse: 0.0568 - log_loss: -1.3366 - var_ratio: 0.4356 - mean_squared_error: 0.0049 - var_loss: 2.2887e-05 - LRFinder: lr = 0.00014667 \n",
      " - LRFinder: lr = 0.00014794 \n",
      " - LRFinder: lr = 0.00014922 \n",
      " - LRFinder: lr = 0.00015051 \n",
      " - LRFinder: lr = 0.00015181 \n",
      " 317/1000 [========>.....................] - ETA: 8s - loss: 0.0049 - rmse: 0.0565 - log_loss: -1.3387 - var_ratio: 0.4385 - mean_squared_error: 0.0049 - var_loss: 2.2681e-05 - LRFinder: lr = 0.00015313 \n",
      " - LRFinder: lr = 0.00015445 \n",
      " - LRFinder: lr = 0.00015578 \n",
      " - LRFinder: lr = 0.00015713 \n",
      " - LRFinder: lr = 0.00015849 \n",
      " 322/1000 [========>.....................] - ETA: 8s - loss: 0.0049 - rmse: 0.0563 - log_loss: -1.3408 - var_ratio: 0.4417 - mean_squared_error: 0.0049 - var_loss: 2.2458e-05 - LRFinder: lr = 0.00015986 \n",
      " - LRFinder: lr = 0.00016124 \n",
      " - LRFinder: lr = 0.00016264 \n",
      " - LRFinder: lr = 0.00016404 \n",
      " - LRFinder: lr = 0.00016546 \n",
      " 327/1000 [========>.....................] - ETA: 8s - loss: 0.0048 - rmse: 0.0561 - log_loss: -1.3429 - var_ratio: 0.4451 - mean_squared_error: 0.0048 - var_loss: 2.2237e-05 - LRFinder: lr = 0.00016689 \n",
      " - LRFinder: lr = 0.00016833 \n",
      " - LRFinder: lr = 0.00016979 \n",
      " - LRFinder: lr = 0.00017126 \n",
      " - LRFinder: lr = 0.00017274 \n",
      " 332/1000 [========>.....................] - ETA: 8s - loss: 0.0048 - rmse: 0.0559 - log_loss: -1.3449 - var_ratio: 0.4479 - mean_squared_error: 0.0048 - var_loss: 2.2039e-05 - LRFinder: lr = 0.00017423 \n",
      " - LRFinder: lr = 0.00017574 \n",
      " - LRFinder: lr = 0.00017725 \n",
      " - LRFinder: lr = 0.00017879 \n",
      " - LRFinder: lr = 0.00018033 \n",
      " 337/1000 [=========>....................] - ETA: 8s - loss: 0.0048 - rmse: 0.0557 - log_loss: -1.3469 - var_ratio: 0.4512 - mean_squared_error: 0.0048 - var_loss: 2.1814e-05 - LRFinder: lr = 0.00018189 \n",
      " - LRFinder: lr = 0.00018346 \n",
      " - LRFinder: lr = 0.00018505 \n",
      " - LRFinder: lr = 0.00018665 \n",
      " - LRFinder: lr = 0.00018826 \n",
      " 342/1000 [=========>....................] - ETA: 8s - loss: 0.0047 - rmse: 0.0555 - log_loss: -1.3488 - var_ratio: 0.4540 - mean_squared_error: 0.0047 - var_loss: 2.1619e-05 - LRFinder: lr = 0.00018989 \n",
      " - LRFinder: lr = 0.00019153 \n",
      " - LRFinder: lr = 0.00019319 \n",
      " - LRFinder: lr = 0.00019486 \n",
      " - LRFinder: lr = 0.00019654 \n",
      " 347/1000 [=========>....................] - ETA: 7s - loss: 0.0047 - rmse: 0.0553 - log_loss: -1.3508 - var_ratio: 0.4570 - mean_squared_error: 0.0047 - var_loss: 2.1404e-05 - LRFinder: lr = 0.00019824 \n",
      " - LRFinder: lr = 0.00019996 \n",
      " - LRFinder: lr = 0.00020168 \n",
      " - LRFinder: lr = 0.00020343 \n",
      " - LRFinder: lr = 0.00020519 \n",
      " - LRFinder: lr = 0.00020696 \n",
      " 353/1000 [=========>....................] - ETA: 7s - loss: 0.0047 - rmse: 0.0550 - log_loss: -1.3531 - var_ratio: 0.4606 - mean_squared_error: 0.0047 - var_loss: 2.1163e-05 - LRFinder: lr = 0.00020875 \n",
      " - LRFinder: lr = 0.00021055 \n",
      " - LRFinder: lr = 0.00021237 \n",
      " - LRFinder: lr = 0.00021421 \n",
      " - LRFinder: lr = 0.00021606 \n",
      " 358/1000 [=========>....................] - ETA: 7s - loss: 0.0047 - rmse: 0.0548 - log_loss: -1.3550 - var_ratio: 0.4630 - mean_squared_error: 0.0047 - var_loss: 2.0987e-05 - LRFinder: lr = 0.00021793 \n",
      " - LRFinder: lr = 0.00021981 \n",
      " - LRFinder: lr = 0.00022171 \n",
      " - LRFinder: lr = 0.00022363 \n",
      " - LRFinder: lr = 0.00022556 \n",
      " - LRFinder: lr = 0.00022751 \n",
      " 364/1000 [=========>....................] - ETA: 7s - loss: 0.0046 - rmse: 0.0546 - log_loss: -1.3569 - var_ratio: 0.4654 - mean_squared_error: 0.0046 - var_loss: 2.0808e-05 - LRFinder: lr = 0.00022948 \n",
      " - LRFinder: lr = 0.00023147 \n",
      " - LRFinder: lr = 0.00023347 \n",
      " - LRFinder: lr = 0.00023548 \n",
      " 368/1000 [==========>...................] - ETA: 7s - loss: 0.0046 - rmse: 0.0545 - log_loss: -1.3582 - var_ratio: 0.4678 - mean_squared_error: 0.0046 - var_loss: 2.0664e-05 - LRFinder: lr = 0.00023752 \n",
      " - LRFinder: lr = 0.00023957 \n",
      " - LRFinder: lr = 0.00024164 \n",
      " - LRFinder: lr = 0.00024373 \n",
      " - LRFinder: lr = 0.00024584 \n",
      " - LRFinder: lr = 0.00024797 \n",
      " 374/1000 [==========>...................] - ETA: 7s - loss: 0.0046 - rmse: 0.0543 - log_loss: -1.3602 - var_ratio: 0.4701 - mean_squared_error: 0.0046 - var_loss: 2.0496e-05 - LRFinder: lr = 0.00025011 \n",
      " - LRFinder: lr = 0.00025227 \n",
      " - LRFinder: lr = 0.00025445 \n",
      " - LRFinder: lr = 0.00025665 \n",
      " - LRFinder: lr = 0.00025887 \n",
      " 379/1000 [==========>...................] - ETA: 7s - loss: 0.0046 - rmse: 0.0541 - log_loss: -1.3617 - var_ratio: 0.4722 - mean_squared_error: 0.0046 - var_loss: 2.0346e-05 - LRFinder: lr = 0.00026111 \n",
      " - LRFinder: lr = 0.00026337 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - LRFinder: lr = 0.00026564 \n",
      " - LRFinder: lr = 0.00026794 \n",
      " - LRFinder: lr = 0.00027026 \n",
      " 384/1000 [==========>...................] - ETA: 7s - loss: 0.0045 - rmse: 0.0540 - log_loss: -1.3633 - var_ratio: 0.4745 - mean_squared_error: 0.0045 - var_loss: 2.0193e-05 - LRFinder: lr = 0.00027259 \n",
      " - LRFinder: lr = 0.00027495 \n",
      " - LRFinder: lr = 0.00027733 \n",
      " - LRFinder: lr = 0.00027972 \n",
      " - LRFinder: lr = 0.00028214 \n",
      " 389/1000 [==========>...................] - ETA: 7s - loss: 0.0045 - rmse: 0.0538 - log_loss: -1.3649 - var_ratio: 0.4769 - mean_squared_error: 0.0045 - var_loss: 2.0021e-05 - LRFinder: lr = 0.00028458 \n",
      " - LRFinder: lr = 0.00028704 \n",
      " - LRFinder: lr = 0.00028952 \n",
      " - LRFinder: lr = 0.00029203 \n",
      " - LRFinder: lr = 0.00029455 \n",
      " 394/1000 [==========>...................] - ETA: 7s - loss: 0.0045 - rmse: 0.0537 - log_loss: -1.3665 - var_ratio: 0.4792 - mean_squared_error: 0.0045 - var_loss: 1.9873e-05 - LRFinder: lr = 0.00029710 \n",
      " - LRFinder: lr = 0.00029966 \n",
      " - LRFinder: lr = 0.00030225 \n",
      " - LRFinder: lr = 0.00030487 \n",
      " - LRFinder: lr = 0.00030750 \n",
      " - LRFinder: lr = 0.00031016 \n",
      " 400/1000 [===========>..................] - ETA: 7s - loss: 0.0045 - rmse: 0.0534 - log_loss: -1.3685 - var_ratio: 0.4820 - mean_squared_error: 0.0045 - var_loss: 1.9673e-05 - LRFinder: lr = 0.00031284 \n",
      " - LRFinder: lr = 0.00031555 \n",
      " - LRFinder: lr = 0.00031828 \n",
      " - LRFinder: lr = 0.00032103 \n",
      " - LRFinder: lr = 0.00032380 \n",
      " 405/1000 [===========>..................] - ETA: 7s - loss: 0.0045 - rmse: 0.0533 - log_loss: -1.3698 - var_ratio: 0.4839 - mean_squared_error: 0.0045 - var_loss: 1.9539e-05 - LRFinder: lr = 0.00032660 \n",
      " - LRFinder: lr = 0.00032943 \n",
      " - LRFinder: lr = 0.00033227 \n",
      " - LRFinder: lr = 0.00033515 \n",
      " 409/1000 [===========>..................] - ETA: 7s - loss: 0.0044 - rmse: 0.0532 - log_loss: -1.3711 - var_ratio: 0.4862 - mean_squared_error: 0.0044 - var_loss: 1.9399e-05 - LRFinder: lr = 0.00033804 \n",
      " - LRFinder: lr = 0.00034097 \n",
      " - LRFinder: lr = 0.00034391 \n",
      " - LRFinder: lr = 0.00034689 \n",
      " - LRFinder: lr = 0.00034988 \n",
      " 414/1000 [===========>..................] - ETA: 7s - loss: 0.0044 - rmse: 0.0530 - log_loss: -1.3726 - var_ratio: 0.4881 - mean_squared_error: 0.0044 - var_loss: 1.9260e-05 - LRFinder: lr = 0.00035291 \n",
      " - LRFinder: lr = 0.00035596 \n",
      " - LRFinder: lr = 0.00035904 \n",
      " - LRFinder: lr = 0.00036214 \n",
      " - LRFinder: lr = 0.00036527 \n",
      " 419/1000 [===========>..................] - ETA: 6s - loss: 0.0044 - rmse: 0.0529 - log_loss: -1.3741 - var_ratio: 0.4903 - mean_squared_error: 0.0044 - var_loss: 1.9119e-05 - LRFinder: lr = 0.00036843 \n",
      " - LRFinder: lr = 0.00037161 \n",
      " - LRFinder: lr = 0.00037483 \n",
      " - LRFinder: lr = 0.00037807 \n",
      " - LRFinder: lr = 0.00038134 \n",
      " 424/1000 [===========>..................] - ETA: 6s - loss: 0.0044 - rmse: 0.0527 - log_loss: -1.3755 - var_ratio: 0.4917 - mean_squared_error: 0.0044 - var_loss: 1.9019e-05 - LRFinder: lr = 0.00038463 \n",
      " - LRFinder: lr = 0.00038796 \n",
      " - LRFinder: lr = 0.00039131 \n",
      " - LRFinder: lr = 0.00039469 \n",
      " - LRFinder: lr = 0.00039811 \n",
      " - LRFinder: lr = 0.00040155 \n",
      " 430/1000 [===========>..................] - ETA: 6s - loss: 0.0044 - rmse: 0.0526 - log_loss: -1.3770 - var_ratio: 0.4939 - mean_squared_error: 0.0044 - var_loss: 1.8867e-05 - LRFinder: lr = 0.00040502 \n",
      " - LRFinder: lr = 0.00040852 \n",
      " - LRFinder: lr = 0.00041205 \n",
      " - LRFinder: lr = 0.00041562 \n",
      " - LRFinder: lr = 0.00041921 \n",
      " 435/1000 [============>.................] - ETA: 6s - loss: 0.0043 - rmse: 0.0524 - log_loss: -1.3782 - var_ratio: 0.4960 - mean_squared_error: 0.0043 - var_loss: 1.8721e-05 - LRFinder: lr = 0.00042283 \n",
      " - LRFinder: lr = 0.00042649 \n",
      " - LRFinder: lr = 0.00043017 \n",
      " - LRFinder: lr = 0.00043389 \n",
      " - LRFinder: lr = 0.00043764 \n",
      " 440/1000 [============>.................] - ETA: 6s - loss: 0.0043 - rmse: 0.0523 - log_loss: -1.3795 - var_ratio: 0.4974 - mean_squared_error: 0.0043 - var_loss: 1.8636e-05 - LRFinder: lr = 0.00044143 \n",
      " - LRFinder: lr = 0.00044524 \n",
      " - LRFinder: lr = 0.00044909 \n",
      " - LRFinder: lr = 0.00045298 \n",
      " - LRFinder: lr = 0.00045689 \n",
      " 445/1000 [============>.................] - ETA: 6s - loss: 0.0043 - rmse: 0.0522 - log_loss: -1.3805 - var_ratio: 0.4993 - mean_squared_error: 0.0043 - var_loss: 1.8513e-05 - LRFinder: lr = 0.00046084 \n",
      " - LRFinder: lr = 0.00046482 \n",
      " - LRFinder: lr = 0.00046884 \n",
      " - LRFinder: lr = 0.00047290 \n",
      " - LRFinder: lr = 0.00047698 \n",
      " 450/1000 [============>.................] - ETA: 6s - loss: 0.0043 - rmse: 0.0521 - log_loss: -1.3817 - var_ratio: 0.5013 - mean_squared_error: 0.0043 - var_loss: 1.8390e-05 - LRFinder: lr = 0.00048111 \n",
      " - LRFinder: lr = 0.00048527 \n",
      " - LRFinder: lr = 0.00048946 \n",
      " - LRFinder: lr = 0.00049369 \n",
      " - LRFinder: lr = 0.00049796 \n",
      " 455/1000 [============>.................] - ETA: 6s - loss: 0.0043 - rmse: 0.0520 - log_loss: -1.3828 - var_ratio: 0.5023 - mean_squared_error: 0.0043 - var_loss: 1.8340e-05 - LRFinder: lr = 0.00050227 \n",
      " - LRFinder: lr = 0.00050661 \n",
      " - LRFinder: lr = 0.00051099 \n",
      " - LRFinder: lr = 0.00051541 \n",
      " - LRFinder: lr = 0.00051986 \n",
      " 460/1000 [============>.................] - ETA: 6s - loss: 0.0043 - rmse: 0.0519 - log_loss: -1.3840 - var_ratio: 0.5036 - mean_squared_error: 0.0043 - var_loss: 1.8266e-05 - LRFinder: lr = 0.00052436 \n",
      " - LRFinder: lr = 0.00052889 \n",
      " - LRFinder: lr = 0.00053346 \n",
      " - LRFinder: lr = 0.00053807 \n",
      " - LRFinder: lr = 0.00054272 \n",
      " 465/1000 [============>.................] - ETA: 6s - loss: 0.0043 - rmse: 0.0518 - log_loss: -1.3850 - var_ratio: 0.5056 - mean_squared_error: 0.0043 - var_loss: 1.8139e-05 - LRFinder: lr = 0.00054742 \n",
      " - LRFinder: lr = 0.00055215 \n",
      " - LRFinder: lr = 0.00055692 \n",
      " - LRFinder: lr = 0.00056174 \n",
      " - LRFinder: lr = 0.00056659 \n",
      " 470/1000 [=============>................] - ETA: 6s - loss: 0.0042 - rmse: 0.0517 - log_loss: -1.3861 - var_ratio: 0.5074 - mean_squared_error: 0.0042 - var_loss: 1.8038e-05 - LRFinder: lr = 0.00057149 \n",
      " - LRFinder: lr = 0.00057643 \n",
      " - LRFinder: lr = 0.00058141 \n",
      " - LRFinder: lr = 0.00058644 \n",
      " - LRFinder: lr = 0.00059151 \n",
      " - LRFinder: lr = 0.00059662 \n",
      " 476/1000 [=============>................] - ETA: 6s - loss: 0.0042 - rmse: 0.0515 - log_loss: -1.3875 - var_ratio: 0.5090 - mean_squared_error: 0.0042 - var_loss: 1.7924e-05 - LRFinder: lr = 0.00060178 \n",
      " - LRFinder: lr = 0.00060698 \n",
      " - LRFinder: lr = 0.00061223 \n",
      " - LRFinder: lr = 0.00061752 \n",
      " - LRFinder: lr = 0.00062286 \n",
      " 481/1000 [=============>................] - ETA: 6s - loss: 0.0042 - rmse: 0.0514 - log_loss: -1.3886 - var_ratio: 0.5106 - mean_squared_error: 0.0042 - var_loss: 1.7817e-05 - LRFinder: lr = 0.00062825 \n",
      " - LRFinder: lr = 0.00063368 \n",
      " - LRFinder: lr = 0.00063916 \n",
      " - LRFinder: lr = 0.00064468 \n",
      " - LRFinder: lr = 0.00065026 \n",
      " 486/1000 [=============>................] - ETA: 6s - loss: 0.0042 - rmse: 0.0513 - log_loss: -1.3897 - var_ratio: 0.5124 - mean_squared_error: 0.0042 - var_loss: 1.7699e-05 - LRFinder: lr = 0.00065588 \n",
      " - LRFinder: lr = 0.00066155 \n",
      " - LRFinder: lr = 0.00066727 \n",
      " - LRFinder: lr = 0.00067303 \n",
      " - LRFinder: lr = 0.00067885 \n",
      " - LRFinder: lr = 0.00068472 \n",
      " 492/1000 [=============>................] - ETA: 5s - loss: 0.0042 - rmse: 0.0512 - log_loss: -1.3910 - var_ratio: 0.5143 - mean_squared_error: 0.0042 - var_loss: 1.7575e-05 - LRFinder: lr = 0.00069064 \n",
      " - LRFinder: lr = 0.00069661 \n",
      " - LRFinder: lr = 0.00070263 \n",
      " - LRFinder: lr = 0.00070871 \n",
      " - LRFinder: lr = 0.00071483 \n",
      " 497/1000 [=============>................] - ETA: 5s - loss: 0.0042 - rmse: 0.0511 - log_loss: -1.3921 - var_ratio: 0.5157 - mean_squared_error: 0.0042 - var_loss: 1.7469e-05 - LRFinder: lr = 0.00072101 \n",
      " - LRFinder: lr = 0.00072725 \n",
      " - LRFinder: lr = 0.00073353 \n",
      " - LRFinder: lr = 0.00073988 \n",
      " - LRFinder: lr = 0.00074627 \n",
      " - LRFinder: lr = 0.00075272 \n",
      " 503/1000 [==============>...............] - ETA: 5s - loss: 0.0041 - rmse: 0.0509 - log_loss: -1.3933 - var_ratio: 0.5171 - mean_squared_error: 0.0041 - var_loss: 1.7376e-05 - LRFinder: lr = 0.00075923 \n",
      " - LRFinder: lr = 0.00076579 \n",
      " - LRFinder: lr = 0.00077241 \n",
      " - LRFinder: lr = 0.00077909 \n",
      " - LRFinder: lr = 0.00078583 \n",
      " 508/1000 [==============>...............] - ETA: 5s - loss: 0.0041 - rmse: 0.0508 - log_loss: -1.3944 - var_ratio: 0.5187 - mean_squared_error: 0.0041 - var_loss: 1.7273e-05 - LRFinder: lr = 0.00079262 \n",
      " - LRFinder: lr = 0.00079947 \n",
      " - LRFinder: lr = 0.00080638 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - LRFinder: lr = 0.00081335 \n",
      " - LRFinder: lr = 0.00082039 \n",
      " - LRFinder: lr = 0.00082748 \n",
      " 514/1000 [==============>...............] - ETA: 5s - loss: 0.0041 - rmse: 0.0507 - log_loss: -1.3956 - var_ratio: 0.5203 - mean_squared_error: 0.0041 - var_loss: 1.7173e-05 - LRFinder: lr = 0.00083463 \n",
      " - LRFinder: lr = 0.00084185 \n",
      " - LRFinder: lr = 0.00084912 \n",
      " - LRFinder: lr = 0.00085647 \n",
      " 518/1000 [==============>...............] - ETA: 5s - loss: 0.0041 - rmse: 0.0506 - log_loss: -1.3964 - var_ratio: 0.5211 - mean_squared_error: 0.0041 - var_loss: 1.7109e-05 - LRFinder: lr = 0.00086387 \n",
      " - LRFinder: lr = 0.00087134 \n",
      " - LRFinder: lr = 0.00087887 \n",
      " - LRFinder: lr = 0.00088647 \n",
      " - LRFinder: lr = 0.00089413 \n",
      " 523/1000 [==============>...............] - ETA: 5s - loss: 0.0041 - rmse: 0.0506 - log_loss: -1.3973 - var_ratio: 0.5225 - mean_squared_error: 0.0041 - var_loss: 1.7027e-05 - LRFinder: lr = 0.00090186 \n",
      " - LRFinder: lr = 0.00090966 \n",
      " - LRFinder: lr = 0.00091752 \n",
      " - LRFinder: lr = 0.00092545 \n",
      " - LRFinder: lr = 0.00093345 \n",
      " 528/1000 [==============>...............] - ETA: 5s - loss: 0.0041 - rmse: 0.0505 - log_loss: -1.3982 - var_ratio: 0.5239 - mean_squared_error: 0.0041 - var_loss: 1.6943e-05 - LRFinder: lr = 0.00094152 \n",
      " - LRFinder: lr = 0.00094966 \n",
      " - LRFinder: lr = 0.00095787 \n",
      " - LRFinder: lr = 0.00096615 \n",
      " - LRFinder: lr = 0.00097451 \n",
      " 533/1000 [==============>...............] - ETA: 5s - loss: 0.0041 - rmse: 0.0504 - log_loss: -1.3991 - var_ratio: 0.5247 - mean_squared_error: 0.0041 - var_loss: 1.6873e-05 - LRFinder: lr = 0.00098293 \n",
      " - LRFinder: lr = 0.00099143 \n",
      " - LRFinder: lr = 0.00100000 \n",
      " - LRFinder: lr = 0.00100864 \n",
      " - LRFinder: lr = 0.00101736 \n",
      " 538/1000 [===============>..............] - ETA: 5s - loss: 0.0041 - rmse: 0.0503 - log_loss: -1.4000 - var_ratio: 0.5264 - mean_squared_error: 0.0041 - var_loss: 1.6762e-05 - LRFinder: lr = 0.00102616 \n",
      " - LRFinder: lr = 0.00103503 \n",
      " - LRFinder: lr = 0.00104398 \n",
      " - LRFinder: lr = 0.00105300 \n",
      " - LRFinder: lr = 0.00106211 \n",
      " 543/1000 [===============>..............] - ETA: 5s - loss: 0.0041 - rmse: 0.0502 - log_loss: -1.4008 - var_ratio: 0.5275 - mean_squared_error: 0.0041 - var_loss: 1.6705e-05 - LRFinder: lr = 0.00107129 \n",
      " - LRFinder: lr = 0.00108055 \n",
      " - LRFinder: lr = 0.00108989 \n",
      " - LRFinder: lr = 0.00109931 \n",
      " - LRFinder: lr = 0.00110882 \n",
      " 548/1000 [===============>..............] - ETA: 5s - loss: 0.0040 - rmse: 0.0501 - log_loss: -1.4017 - var_ratio: 0.5286 - mean_squared_error: 0.0040 - var_loss: 1.6627e-05 - LRFinder: lr = 0.00111840 \n",
      " - LRFinder: lr = 0.00112807 \n",
      " - LRFinder: lr = 0.00113782 \n",
      " - LRFinder: lr = 0.00114766 \n",
      " - LRFinder: lr = 0.00115758 \n",
      " 553/1000 [===============>..............] - ETA: 5s - loss: 0.0040 - rmse: 0.0500 - log_loss: -1.4026 - var_ratio: 0.5299 - mean_squared_error: 0.0040 - var_loss: 1.6537e-05 - LRFinder: lr = 0.00116759 \n",
      " - LRFinder: lr = 0.00117768 \n",
      " - LRFinder: lr = 0.00118786 \n",
      " - LRFinder: lr = 0.00119813 \n",
      " - LRFinder: lr = 0.00120849 \n",
      " 558/1000 [===============>..............] - ETA: 5s - loss: 0.0040 - rmse: 0.0499 - log_loss: -1.4034 - var_ratio: 0.5312 - mean_squared_error: 0.0040 - var_loss: 1.6446e-05 - LRFinder: lr = 0.00121894 \n",
      " - LRFinder: lr = 0.00122947 \n",
      " - LRFinder: lr = 0.00124010 \n",
      " - LRFinder: lr = 0.00125082 \n",
      " - LRFinder: lr = 0.00126164 \n",
      " 563/1000 [===============>..............] - ETA: 5s - loss: 0.0040 - rmse: 0.0498 - log_loss: -1.4043 - var_ratio: 0.5323 - mean_squared_error: 0.0040 - var_loss: 1.6372e-05 - LRFinder: lr = 0.00127254 \n",
      " - LRFinder: lr = 0.00128354 \n",
      " - LRFinder: lr = 0.00129464 \n",
      " - LRFinder: lr = 0.00130583 \n",
      " - LRFinder: lr = 0.00131712 \n",
      " 568/1000 [================>.............] - ETA: 5s - loss: 0.0040 - rmse: 0.0498 - log_loss: -1.4051 - var_ratio: 0.5334 - mean_squared_error: 0.0040 - var_loss: 1.6295e-05 - LRFinder: lr = 0.00132851 \n",
      " - LRFinder: lr = 0.00133999 \n",
      " - LRFinder: lr = 0.00135158 \n",
      " - LRFinder: lr = 0.00136326 \n",
      " - LRFinder: lr = 0.00137505 \n",
      " 573/1000 [================>.............] - ETA: 4s - loss: 0.0040 - rmse: 0.0497 - log_loss: -1.4058 - var_ratio: 0.5343 - mean_squared_error: 0.0040 - var_loss: 1.6224e-05 - LRFinder: lr = 0.00138693 \n",
      " - LRFinder: lr = 0.00139892 \n",
      " - LRFinder: lr = 0.00141102 \n",
      " - LRFinder: lr = 0.00142321 \n",
      " 577/1000 [================>.............] - ETA: 4s - loss: 0.0040 - rmse: 0.0496 - log_loss: -1.4064 - var_ratio: 0.5352 - mean_squared_error: 0.0040 - var_loss: 1.6166e-05 - LRFinder: lr = 0.00143552 \n",
      " - LRFinder: lr = 0.00144793 \n",
      " - LRFinder: lr = 0.00146045 \n",
      " - LRFinder: lr = 0.00147307 \n",
      " - LRFinder: lr = 0.00148581 \n",
      " - LRFinder: lr = 0.00149865 \n",
      " 583/1000 [================>.............] - ETA: 4s - loss: 0.0040 - rmse: 0.0495 - log_loss: -1.4074 - var_ratio: 0.5366 - mean_squared_error: 0.0040 - var_loss: 1.6074e-05 - LRFinder: lr = 0.00151161 \n",
      " - LRFinder: lr = 0.00152467 \n",
      " - LRFinder: lr = 0.00153785 \n",
      " - LRFinder: lr = 0.00155115 \n",
      " - LRFinder: lr = 0.00156456 \n",
      " 588/1000 [================>.............] - ETA: 4s - loss: 0.0039 - rmse: 0.0494 - log_loss: -1.4083 - var_ratio: 0.5379 - mean_squared_error: 0.0039 - var_loss: 1.5985e-05 - LRFinder: lr = 0.00157808 \n",
      " - LRFinder: lr = 0.00159173 \n",
      " - LRFinder: lr = 0.00160549 \n",
      " - LRFinder: lr = 0.00161937 \n",
      " - LRFinder: lr = 0.00163337 \n",
      " 593/1000 [================>.............] - ETA: 4s - loss: 0.0039 - rmse: 0.0494 - log_loss: -1.4089 - var_ratio: 0.5392 - mean_squared_error: 0.0039 - var_loss: 1.5910e-05 - LRFinder: lr = 0.00164749 \n",
      " - LRFinder: lr = 0.00166173 \n",
      " - LRFinder: lr = 0.00167609 \n",
      " - LRFinder: lr = 0.00169058 \n",
      " 597/1000 [================>.............] - ETA: 4s - loss: 0.0039 - rmse: 0.0493 - log_loss: -1.4094 - var_ratio: 0.5401 - mean_squared_error: 0.0039 - var_loss: 1.5856e-05 - LRFinder: lr = 0.00170520 \n",
      " - LRFinder: lr = 0.00171994 \n",
      " - LRFinder: lr = 0.00173481 \n",
      " - LRFinder: lr = 0.00174981 \n",
      " - LRFinder: lr = 0.00176493 \n",
      " 602/1000 [=================>............] - ETA: 4s - loss: 0.0039 - rmse: 0.0493 - log_loss: -1.4096 - var_ratio: 0.5406 - mean_squared_error: 0.0039 - var_loss: 1.5813e-05 - LRFinder: lr = 0.00178019 \n",
      " - LRFinder: lr = 0.00179558 \n",
      " - LRFinder: lr = 0.00181110 \n",
      " - LRFinder: lr = 0.00182676 \n",
      " 606/1000 [=================>............] - ETA: 4s - loss: 0.0039 - rmse: 0.0492 - log_loss: -1.4101 - var_ratio: 0.5417 - mean_squared_error: 0.0039 - var_loss: 1.5739e-05 - LRFinder: lr = 0.00184255 \n",
      " - LRFinder: lr = 0.00185848 \n",
      " - LRFinder: lr = 0.00187455 \n",
      " - LRFinder: lr = 0.00189075 \n",
      " - LRFinder: lr = 0.00190710 \n",
      " 611/1000 [=================>............] - ETA: 4s - loss: 0.0039 - rmse: 0.0492 - log_loss: -1.4106 - var_ratio: 0.5420 - mean_squared_error: 0.0039 - var_loss: 1.5735e-05 - LRFinder: lr = 0.00192359 \n",
      " - LRFinder: lr = 0.00194021 \n",
      " - LRFinder: lr = 0.00195699 \n",
      " - LRFinder: lr = 0.00197391 \n",
      " - LRFinder: lr = 0.00199097 \n",
      " 616/1000 [=================>............] - ETA: 4s - loss: 0.0039 - rmse: 0.0491 - log_loss: -1.4110 - var_ratio: 0.5431 - mean_squared_error: 0.0039 - var_loss: 1.5664e-05 - LRFinder: lr = 0.00200818 \n",
      " - LRFinder: lr = 0.00202554 \n",
      " - LRFinder: lr = 0.00204305 \n",
      " - LRFinder: lr = 0.00206072 \n",
      " - LRFinder: lr = 0.00207853 \n",
      " - LRFinder: lr = 0.00209650 \n",
      " 622/1000 [=================>............] - ETA: 4s - loss: 0.0039 - rmse: 0.0490 - log_loss: -1.4117 - var_ratio: 0.5442 - mean_squared_error: 0.0039 - var_loss: 1.5586e-05 - LRFinder: lr = 0.00211462 \n",
      " - LRFinder: lr = 0.00213290 \n",
      " - LRFinder: lr = 0.00215134 \n",
      " - LRFinder: lr = 0.00216994 \n",
      " - LRFinder: lr = 0.00218870 \n",
      " - LRFinder: lr = 0.00220762 \n",
      " 628/1000 [=================>............] - ETA: 4s - loss: 0.0039 - rmse: 0.0490 - log_loss: -1.4125 - var_ratio: 0.5453 - mean_squared_error: 0.0039 - var_loss: 1.5524e-05 - LRFinder: lr = 0.00222671 \n",
      " - LRFinder: lr = 0.00224596 \n",
      " - LRFinder: lr = 0.00226537 \n",
      " - LRFinder: lr = 0.00228496 \n",
      " - LRFinder: lr = 0.00230471 \n",
      " 633/1000 [=================>............] - ETA: 4s - loss: 0.0039 - rmse: 0.0489 - log_loss: -1.4131 - var_ratio: 0.5461 - mean_squared_error: 0.0039 - var_loss: 1.5462e-05 - LRFinder: lr = 0.00232463 \n",
      " - LRFinder: lr = 0.00234473 \n",
      " - LRFinder: lr = 0.00236500 \n",
      " - LRFinder: lr = 0.00238544 \n",
      " - LRFinder: lr = 0.00240607 \n",
      " - LRFinder: lr = 0.00242687 \n",
      " 639/1000 [==================>...........] - ETA: 4s - loss: 0.0039 - rmse: 0.0488 - log_loss: -1.4137 - var_ratio: 0.5471 - mean_squared_error: 0.0039 - var_loss: 1.5404e-05 - LRFinder: lr = 0.00244785 \n",
      " - LRFinder: lr = 0.00246901 \n",
      " - LRFinder: lr = 0.00249035 \n",
      " - LRFinder: lr = 0.00251188 \n",
      " - LRFinder: lr = 0.00253360 \n",
      " 644/1000 [==================>...........] - ETA: 4s - loss: 0.0039 - rmse: 0.0488 - log_loss: -1.4142 - var_ratio: 0.5482 - mean_squared_error: 0.0039 - var_loss: 1.5346e-05 - LRFinder: lr = 0.00255550 \n",
      " - LRFinder: lr = 0.00257759 \n",
      " - LRFinder: lr = 0.00259988 \n",
      " - LRFinder: lr = 0.00262235 \n",
      " - LRFinder: lr = 0.00264502 \n",
      " 649/1000 [==================>...........] - ETA: 4s - loss: 0.0038 - rmse: 0.0487 - log_loss: -1.4147 - var_ratio: 0.5489 - mean_squared_error: 0.0038 - var_loss: 1.5298e-05 - LRFinder: lr = 0.00266789 \n",
      " - LRFinder: lr = 0.00269095 \n",
      " - LRFinder: lr = 0.00271421 \n",
      " - LRFinder: lr = 0.00273768 \n",
      " - LRFinder: lr = 0.00276135 \n",
      " - LRFinder: lr = 0.00278522 \n",
      " 655/1000 [==================>...........] - ETA: 3s - loss: 0.0038 - rmse: 0.0487 - log_loss: -1.4152 - var_ratio: 0.5497 - mean_squared_error: 0.0038 - var_loss: 1.5242e-05 - LRFinder: lr = 0.00280930 \n",
      " - LRFinder: lr = 0.00283358 \n",
      " - LRFinder: lr = 0.00285808 \n",
      " - LRFinder: lr = 0.00288279 \n",
      " - LRFinder: lr = 0.00290771 \n",
      " 660/1000 [==================>...........] - ETA: 3s - loss: 0.0038 - rmse: 0.0486 - log_loss: -1.4156 - var_ratio: 0.5510 - mean_squared_error: 0.0038 - var_loss: 1.5194e-05 - LRFinder: lr = 0.00293284 \n",
      " - LRFinder: lr = 0.00295820 \n",
      " - LRFinder: lr = 0.00298377 \n",
      " - LRFinder: lr = 0.00300957 \n",
      " - LRFinder: lr = 0.00303558 \n",
      " 665/1000 [==================>...........] - ETA: 3s - loss: 0.0038 - rmse: 0.0486 - log_loss: -1.4160 - var_ratio: 0.5514 - mean_squared_error: 0.0038 - var_loss: 1.5167e-05 - LRFinder: lr = 0.00306183 \n",
      " - LRFinder: lr = 0.00308830 \n",
      " - LRFinder: lr = 0.00311499 \n",
      " - LRFinder: lr = 0.00314192 \n",
      " - LRFinder: lr = 0.00316908 \n",
      " - LRFinder: lr = 0.00319648 \n",
      " 671/1000 [===================>..........] - ETA: 3s - loss: 0.0038 - rmse: 0.0485 - log_loss: -1.4164 - var_ratio: 0.5527 - mean_squared_error: 0.0038 - var_loss: 1.5098e-05 - LRFinder: lr = 0.00322411 \n",
      " - LRFinder: lr = 0.00325199 \n",
      " - LRFinder: lr = 0.00328010 \n",
      " - LRFinder: lr = 0.00330846 \n",
      " - LRFinder: lr = 0.00333706 \n",
      " - LRFinder: lr = 0.00336591 \n",
      " 677/1000 [===================>..........] - ETA: 3s - loss: 0.0038 - rmse: 0.0485 - log_loss: -1.4166 - var_ratio: 0.5528 - mean_squared_error: 0.0038 - var_loss: 1.5112e-05 - LRFinder: lr = 0.00339500 \n",
      " - LRFinder: lr = 0.00342435 \n",
      " - LRFinder: lr = 0.00345396 \n",
      " - LRFinder: lr = 0.00348382 \n",
      " - LRFinder: lr = 0.00351393 \n",
      " - LRFinder: lr = 0.00354431 \n",
      " 683/1000 [===================>..........] - ETA: 3s - loss: 0.0038 - rmse: 0.0485 - log_loss: -1.4169 - var_ratio: 0.5533 - mean_squared_error: 0.0038 - var_loss: 1.5066e-05 - LRFinder: lr = 0.00357495 \n",
      " - LRFinder: lr = 0.00360586 \n",
      " - LRFinder: lr = 0.00363703 \n",
      " - LRFinder: lr = 0.00366847 \n",
      " - LRFinder: lr = 0.00370019 \n",
      " - LRFinder: lr = 0.00373217 \n",
      " 689/1000 [===================>..........] - ETA: 3s - loss: 0.0038 - rmse: 0.0484 - log_loss: -1.4174 - var_ratio: 0.5544 - mean_squared_error: 0.0038 - var_loss: 1.4995e-05 - LRFinder: lr = 0.00376444 \n",
      " - LRFinder: lr = 0.00379698 \n",
      " - LRFinder: lr = 0.00382981 \n",
      " - LRFinder: lr = 0.00386291 \n",
      " - LRFinder: lr = 0.00389631 \n",
      " - LRFinder: lr = 0.00392999 \n",
      " 695/1000 [===================>..........] - ETA: 3s - loss: 0.0038 - rmse: 0.0483 - log_loss: -1.4179 - var_ratio: 0.5550 - mean_squared_error: 0.0038 - var_loss: 1.4955e-05 - LRFinder: lr = 0.00396397 \n",
      " - LRFinder: lr = 0.00399824 \n",
      " - LRFinder: lr = 0.00403280 \n",
      " - LRFinder: lr = 0.00406766 \n",
      " - LRFinder: lr = 0.00410283 \n",
      " - LRFinder: lr = 0.00413830 \n",
      " 701/1000 [====================>.........] - ETA: 3s - loss: 0.0038 - rmse: 0.0483 - log_loss: -1.4185 - var_ratio: 0.5560 - mean_squared_error: 0.0038 - var_loss: 1.4891e-05 - LRFinder: lr = 0.00417407 \n",
      " - LRFinder: lr = 0.00421016 \n",
      " - LRFinder: lr = 0.00424655 \n",
      " - LRFinder: lr = 0.00428327 \n",
      " - LRFinder: lr = 0.00432029 \n",
      " - LRFinder: lr = 0.00435764 \n",
      " 707/1000 [====================>.........] - ETA: 3s - loss: 0.0038 - rmse: 0.0482 - log_loss: -1.4191 - var_ratio: 0.5570 - mean_squared_error: 0.0038 - var_loss: 1.4819e-05 - LRFinder: lr = 0.00439531 \n",
      " - LRFinder: lr = 0.00443331 \n",
      " - LRFinder: lr = 0.00447164 \n",
      " - LRFinder: lr = 0.00451029 \n",
      " - LRFinder: lr = 0.00454929 \n",
      " - LRFinder: lr = 0.00458861 \n",
      " 713/1000 [====================>.........] - ETA: 3s - loss: 0.0038 - rmse: 0.0482 - log_loss: -1.4198 - var_ratio: 0.5579 - mean_squared_error: 0.0038 - var_loss: 1.4766e-05 - LRFinder: lr = 0.00462828 \n",
      " - LRFinder: lr = 0.00466829 \n",
      " - LRFinder: lr = 0.00470865 \n",
      " - LRFinder: lr = 0.00474936 \n",
      " - LRFinder: lr = 0.00479042 \n",
      " - LRFinder: lr = 0.00483183 \n",
      " 719/1000 [====================>.........] - ETA: 3s - loss: 0.0038 - rmse: 0.0481 - log_loss: -1.4202 - var_ratio: 0.5586 - mean_squared_error: 0.0038 - var_loss: 1.4726e-05 - LRFinder: lr = 0.00487360 \n",
      " - LRFinder: lr = 0.00491573 \n",
      " - LRFinder: lr = 0.00495823 \n",
      " - LRFinder: lr = 0.00500109 \n",
      " - LRFinder: lr = 0.00504433 \n",
      " 724/1000 [====================>.........] - ETA: 3s - loss: 0.0038 - rmse: 0.0481 - log_loss: -1.4206 - var_ratio: 0.5593 - mean_squared_error: 0.0038 - var_loss: 1.4676e-05 - LRFinder: lr = 0.00508793 \n",
      " - LRFinder: lr = 0.00513192 \n",
      " - LRFinder: lr = 0.00517628 \n",
      " - LRFinder: lr = 0.00522103 \n",
      " - LRFinder: lr = 0.00526617 \n",
      " 729/1000 [====================>.........] - ETA: 3s - loss: 0.0038 - rmse: 0.0480 - log_loss: -1.4208 - var_ratio: 0.5595 - mean_squared_error: 0.0038 - var_loss: 1.4674e-05 - LRFinder: lr = 0.00531169 \n",
      " - LRFinder: lr = 0.00535761 \n",
      " - LRFinder: lr = 0.00540393 \n",
      " - LRFinder: lr = 0.00545065 \n",
      " - LRFinder: lr = 0.00549777 \n",
      " 734/1000 [=====================>........] - ETA: 3s - loss: 0.0037 - rmse: 0.0480 - log_loss: -1.4209 - var_ratio: 0.5598 - mean_squared_error: 0.0037 - var_loss: 1.4661e-05 - LRFinder: lr = 0.00554529 \n",
      " - LRFinder: lr = 0.00559323 \n",
      " - LRFinder: lr = 0.00564159 \n",
      " - LRFinder: lr = 0.00569036 \n",
      " - LRFinder: lr = 0.00573955 \n",
      " 739/1000 [=====================>........] - ETA: 2s - loss: 0.0037 - rmse: 0.0480 - log_loss: -1.4209 - var_ratio: 0.5604 - mean_squared_error: 0.0037 - var_loss: 1.4637e-05 - LRFinder: lr = 0.00578917 \n",
      " - LRFinder: lr = 0.00583921 \n",
      " - LRFinder: lr = 0.00588969 \n",
      " - LRFinder: lr = 0.00594061 \n",
      " - LRFinder: lr = 0.00599197 \n",
      " - LRFinder: lr = 0.00604377 \n",
      " 745/1000 [=====================>........] - ETA: 2s - loss: 0.0037 - rmse: 0.0480 - log_loss: -1.4210 - var_ratio: 0.5607 - mean_squared_error: 0.0037 - var_loss: 1.4613e-05 - LRFinder: lr = 0.00609601 \n",
      " - LRFinder: lr = 0.00614871 \n",
      " - LRFinder: lr = 0.00620187 \n",
      " - LRFinder: lr = 0.00625548 \n",
      " - LRFinder: lr = 0.00630956 \n",
      " 750/1000 [=====================>........] - ETA: 2s - loss: 0.0037 - rmse: 0.0480 - log_loss: -1.4211 - var_ratio: 0.5613 - mean_squared_error: 0.0037 - var_loss: 1.4584e-05 - LRFinder: lr = 0.00636411 \n",
      " - LRFinder: lr = 0.00641913 \n",
      " - LRFinder: lr = 0.00647462 \n",
      " - LRFinder: lr = 0.00653059 \n",
      " - LRFinder: lr = 0.00658705 \n",
      " - LRFinder: lr = 0.00664399 \n",
      " 756/1000 [=====================>........] - ETA: 2s - loss: 0.0037 - rmse: 0.0480 - log_loss: -1.4213 - var_ratio: 0.5617 - mean_squared_error: 0.0037 - var_loss: 1.4556e-05 - LRFinder: lr = 0.00670143 \n",
      " - LRFinder: lr = 0.00675936 \n",
      " - LRFinder: lr = 0.00681780 \n",
      " - LRFinder: lr = 0.00687674 \n",
      " - LRFinder: lr = 0.00693619 \n",
      " - LRFinder: lr = 0.00699615 \n",
      " 762/1000 [=====================>........] - ETA: 2s - loss: 0.0037 - rmse: 0.0479 - log_loss: -1.4215 - var_ratio: 0.5620 - mean_squared_error: 0.0037 - var_loss: 1.4538e-05 - LRFinder: lr = 0.00705663 \n",
      " - LRFinder: lr = 0.00711764 \n",
      " - LRFinder: lr = 0.00717917 \n",
      " - LRFinder: lr = 0.00724123 \n",
      " - LRFinder: lr = 0.00730383 \n",
      " - LRFinder: lr = 0.00736697 \n",
      " 768/1000 [======================>.......] - ETA: 2s - loss: 0.0037 - rmse: 0.0480 - log_loss: -1.4214 - var_ratio: 0.5624 - mean_squared_error: 0.0037 - var_loss: 1.4552e-05 - LRFinder: lr = 0.00743066 \n",
      " - LRFinder: lr = 0.00749490 \n",
      " - LRFinder: lr = 0.00755969 \n",
      " - LRFinder: lr = 0.00762504 \n",
      " - LRFinder: lr = 0.00769096 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 775/1000 [======================>.......] - ETA: 2s - loss: 1.3732 - rmse: 0.0920 - log_loss: -1.4119 - var_ratio: 178.5943 - mean_squared_error: 1.3732 - var_loss: 1358.2080 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 780/1000 [======================>.......] - ETA: 2s - loss: 1103527.2103 - rmse: 33.0798 - log_loss: -1.3841 - var_ratio: 151443152.9508 - mean_squared_error: 1103527.2103 - var_loss: 938481877500781.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 786/1000 [======================>.......] - ETA: 2s - loss: 1016355524.8753 - rmse: 847.5217 - log_loss: -1.3413 - var_ratio: 138517918918.2362 - mean_squared_error: 1016355524.8753 - var_loss: 793148742224341237760.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 792/1000 [======================>.......] - ETA: 2s - loss: 32718833038.3737 - rmse: 8281.4779 - log_loss: -1.2899 - var_ratio: 3898170570403.1182 - mean_squared_error: 32718833038.3737 - var_loss: 406661606617433612746752.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 798/1000 [======================>.......] - ETA: 2s - loss: 863817939241.8546 - rmse: 51044.4338 - log_loss: -1.2330 - var_ratio: 100554632139996.9062 - mean_squared_error: 863817939241.8546 - var_loss: 233981862393504408549720064.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 804/1000 [=======================>......] - ETA: 2s - loss: 1367580979724.8855 - rmse: 93021.0726 - log_loss: -1.1750 - var_ratio: 159520886474010.9375 - mean_squared_error: 1367580979724.8855 - var_loss: 331471001801445160544894976.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 810/1000 [=======================>......] - ETA: 2s - loss: 1483287015449.4321 - rmse: 114507.4912 - log_loss: -1.1193 - var_ratio: 174410738610674.2812 - mean_squared_error: 1483287015449.4321 - var_loss: 334115642857347538197938176.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 816/1000 [=======================>......] - ETA: 2s - loss: 1795056414413.9509 - rmse: 142498.9623 - log_loss: -1.0652 - var_ratio: 214847112812747.5000 - mean_squared_error: 1795056414413.9509 - var_loss: 371743575708840722064998400.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 822/1000 [=======================>......] - ETA: 1s - loss: 1798234806042.9294 - rmse: 151253.7499 - log_loss: -1.0130 - var_ratio: 215312904190886.5000 - mean_squared_error: 1798234806042.9294 - var_loss: 369069748279064404131053568.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 828/1000 [=======================>......] - ETA: 1s - loss: 2453008063062.7148 - rmse: 206687.0645 - log_loss: -0.9566 - var_ratio: 298601466175451.0625 - mean_squared_error: 2453008063062.7148 - var_loss: 471342735443639300037541888.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 833/1000 [=======================>......] - ETA: 1s - loss: 2474921449538.5259 - rmse: 218598.9337 - log_loss: -0.9132 - var_ratio: 300991759932862.4375 - mean_squared_error: 2474921449538.5259 - var_loss: 468763051814804966478970880.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 839/1000 [========================>.....] - ETA: 1s - loss: 2484840899600.0098 - rmse: 228345.4705 - log_loss: -0.8632 - var_ratio: 302310695677813.0625 - mean_squared_error: 2484840899600.0098 - var_loss: 465526462253654957608665088.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 845/1000 [========================>.....] - ETA: 1s - loss: 2477482087010.9067 - rmse: 233915.2417 - log_loss: -0.8151 - var_ratio: 301470838732775.9375 - mean_squared_error: 2477482087010.9067 - var_loss: 462236588604611590331826176.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 851/1000 [========================>.....] - ETA: 1s - loss: 2467812168315.4780 - rmse: 238524.7251 - log_loss: -0.7681 - var_ratio: 300325815949061.8750 - mean_squared_error: 2467812168315.4780 - var_loss: 458987341991269237784576000.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 857/1000 [========================>.....] - ETA: 1s - loss: 2453190666816.0654 - rmse: 240449.0816 - log_loss: -0.7234 - var_ratio: 298544252180093.0625 - mean_squared_error: 2453190666816.0654 - var_loss: 455774987212337554068078592.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 863/1000 [========================>.....] - ETA: 1s - loss: 2437170041249.8076 - rmse: 241094.4154 - log_loss: -0.6805 - var_ratio: 296594503914485.5000 - mean_squared_error: 2437170041249.8076 - var_loss: 452606370531457959595081728.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 869/1000 [=========================>....] - ETA: 1s - loss: 2420905244057.0312 - rmse: 241187.6488 - log_loss: -0.6389 - var_ratio: 294617455340594.8750 - mean_squared_error: 2420905244057.0312 - var_loss: 449481402346127104273285120.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 876/1000 [=========================>....] - ETA: 1s - loss: 2402093159419.4614 - rmse: 241061.5326 - log_loss: -0.5914 - var_ratio: 292328919373443.1250 - mean_squared_error: 2402093159419.4614 - var_loss: 445889693461680572703178752.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 882/1000 [=========================>....] - ETA: 1s - loss: 2386000463651.5464 - rmse: 240581.2464 - log_loss: -0.5521 - var_ratio: 290373720121922.3750 - mean_squared_error: 2386000463651.5464 - var_loss: 442856439553236058410844160.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 888/1000 [=========================>....] - ETA: 1s - loss: 2370028573394.0088 - rmse: 239872.4134 - log_loss: -0.5140 - var_ratio: 288430377005538.1875 - mean_squared_error: 2370028573394.0088 - var_loss: 439864169708995849756868608.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 894/1000 [=========================>....] - ETA: 1s - loss: 2354246624737.2080 - rmse: 239075.5436 - log_loss: -0.4767 - var_ratio: 286509791670705.1250 - mean_squared_error: 2354246624737.2080 - var_loss: 436912063515257101122273280.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 900/1000 [==========================>...] - ETA: 1s - loss: 2338647452209.0576 - rmse: 238199.1968 - log_loss: -0.4403 - var_ratio: 284611882907732.3750 - mean_squared_error: 2338647452209.0576 - var_loss: 433999317868856235901583360.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 906/1000 [==========================>...] - ETA: 1s - loss: 2323240285886.0132 - rmse: 237269.1017 - log_loss: -0.4047 - var_ratio: 282737094213453.6250 - mean_squared_error: 2323240285886.0132 - var_loss: 431125151227825511586594816.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 912/1000 [==========================>...] - ETA: 0s - loss: 2308041616023.7104 - rmse: 236360.8244 - log_loss: -0.3695 - var_ratio: 280888063903926.0625 - mean_squared_error: 2308041616023.7104 - var_loss: 428288802696962940208152576.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 919/1000 [==========================>...] - ETA: 0s - loss: 2290531512891.7432 - rmse: 235207.7046 - log_loss: -0.3294 - var_ratio: 278757210268087.1875 - mean_squared_error: 2290531512891.7432 - var_loss: 425026538262699481317244928.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 925/1000 [==========================>...] - ETA: 0s - loss: 2275725437091.4160 - rmse: 234199.6096 - log_loss: -0.2958 - var_ratio: 276955484734699.9688 - mean_squared_error: 2275725437091.4160 - var_loss: 422269609784761909331886080.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 931/1000 [==========================>...] - ETA: 0s - loss: 2261109063330.3633 - rmse: 233192.6477 - log_loss: -0.2626 - var_ratio: 275176866701129.5938 - mean_squared_error: 2261109063330.3633 - var_loss: 419548216353769084701114368.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 937/1000 [===========================>..] - ETA: 0s - loss: 2246676226203.8589 - rmse: 232181.3017 - log_loss: -0.2300 - var_ratio: 273420487752121.6875 - mean_squared_error: 2246676226203.8589 - var_loss: 416861675286341665410777088.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 943/1000 [===========================>..] - ETA: 0s - loss: 2232427291503.7031 - rmse: 231186.7614 - log_loss: -0.1978 - var_ratio: 271686554039955.3125 - mean_squared_error: 2232427291503.7031 - var_loss: 414209321388067088465133568.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 950/1000 [===========================>..] - ETA: 0s - loss: 2216024428511.2505 - rmse: 230001.5288 - log_loss: -0.1610 - var_ratio: 269690391582890.4688 - mean_squared_error: 2216024428511.2505 - var_loss: 411157253003606984654585856.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 956/1000 [===========================>..] - ETA: 0s - loss: 2202160405390.5859 - rmse: 229024.9526 - log_loss: -0.1297 - var_ratio: 268003477648373.4688 - mean_squared_error: 2202160405390.5859 - var_loss: 408576768478885951515394048.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 962/1000 [===========================>..] - ETA: 0s - loss: 2188462403972.1165 - rmse: 228022.3008 - log_loss: -0.0990 - var_ratio: 266336801067342.4062 - mean_squared_error: 2188462403972.1165 - var_loss: 406028472849436030344888320.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 968/1000 [============================>.] - ETA: 0s - loss: 2174933950541.3472 - rmse: 227031.1335 - log_loss: -0.0687 - var_ratio: 264690494889241.5625 - mean_squared_error: 2174933950541.3472 - var_loss: 403511767657916635235221504.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 974/1000 [============================>.] - ETA: 0s - loss: 2161567541177.6838 - rmse: 226025.4355 - log_loss: -0.0390 - var_ratio: 263063880084084.8750 - mean_squared_error: 2161567541177.6838 - var_loss: 401026069048237989231067136.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 980/1000 [============================>.] - ETA: 0s - loss: 2148366019934.6858 - rmse: 225040.4454 - log_loss: -0.0095 - var_ratio: 261457399978997.7188 - mean_squared_error: 2148366019934.6858 - var_loss: 398570807581235078039076864.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 987/1000 [============================>.] - ETA: 0s - loss: 2133163810661.5359 - rmse: 223883.5449 - log_loss: 0.0242 - var_ratio: 259607574350367.8125 - mean_squared_error: 2133163810661.5359 - var_loss: 395744064438844089106956288.0000  - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " 994/1000 [============================>.] - ETA: 0s - loss: 2118175695870.8330 - rmse: 222740.6195 - log_loss: 0.0574 - var_ratio: 257783574341646.5938 - mean_squared_error: 2118175695870.8330 - var_loss: 392957134579922730515169280.0000 - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      " - LRFinder: Skipping iteration since loss is 50 times as large as best loss (0.0021)\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 2105494394389.3679 - rmse: 221763.7738 - log_loss: 0.0855 - var_ratio: 256240315488110.7500 - mean_squared_error: 2105494394389.3679 - var_loss: 390599391905872426609672192.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f18acae3898>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_gen.return_generator(),   # This actually returns the generator\n",
    "    1000,\n",
    "    epochs=1,\n",
    "    callbacks=[lr_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEPCAYAAABP1MOPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VOW9x/HPmS3bBJKwyioEkU1EalsroiJSFctFXCAFgkorfdXLvVoRd5BGpEj1Wut+awVf1IUW1LZqvZaLCGIRxUslIiJbEBASEsgySWY7z/0jMBLZZmiGJCff918558zM85w5MN/5Pc+ccyxjjEFERFosV2N3QEREGpeCQESkhVMQiIi0cAoCEZEWTkEgItLCKQhERFo4BYE0qJ07d3LOOec0StuPPfYYr7/++ilvd/ny5Tz22GOntM38/HzefvvtU9qmOJensTsg0lBuueWWRml3/fr1lJeXN0rbIg1BQSCnTCgU4uGHH+ajjz4iGo3Sr18/7rvvPvx+P++++y7PPvssoVCIsrIyrrrqKm699VY+/PBDHnzwQdLT0wkEAtxxxx08+eSTdO3alS+//JJIJMIvf/lLvvOd73DXXXdxxhln8JOf/ISzzjqLKVOmsGrVKoqLi/npT3/K+PHjiUajzJs3j2XLlpGZmcnAgQPZsmULCxcurNfXV199lcWLF1NTU4Pf7+fZZ59l1qxZFBUVceDAATIyMnj44YeprKzklVdeIRqNkpmZyS9+8Qv+9Kc/8fLLL2PbNllZWcyYMYPc3Nx6rz9t2jT69+/P5MmTAXjppZdYs2YNDz74IHfffTdFRUW4XC769+9PQUEBLlf8xfuiRYtYuHAhLpeLtm3bMmPGDHr06MHHH3/M3LlzsW0bgJ/97Gdcdtllx1wvLYgRaUBfffWVGTRo0FG3Pf7442bu3LnGtm1jjDGPPPKIuf/++41t22bixIlm27Ztxhhj9uzZY/r27WtKS0vN6tWrTZ8+fczOnTuNMcasXr3a9O3b12zYsMEYY8zvf/97M2HCBGOMMXfeead57rnnjDHG9O7d2yxcuNAYY8z69evNgAEDTG1trXn55ZfNhAkTTG1trQkGg2by5Mlm4sSJR/R1yZIl5rvf/a6prKw0xhjzt7/9zTzwwAOx7TNmzDAFBQXGGGN++9vfml/+8pfGGGM+/PBDM378eFNdXW2MMWblypXm8ssvP+L1//GPf5gf/ehHseVrr73WrFq1yrz22mtm8uTJxhhjIpGIuffee8327duPeP7EiRPN3/72tyPWf/DBB+bSSy81paWlsf244oorjG3bZtKkSeaNN94wxhjz+eefm1mzZhljzDHXS8uhikBOmeXLl1NZWckHH3wAQDgcpk2bNliWxTPPPMPy5ct544032LJlC8YYampqADjttNPo3Llz7HU6depE3759AejXrx+vvfbaUdsbPnw4AP379ycUClFdXc17773H6NGjSUlJAWDcuHFHVAOHnHnmmfj9fgAuv/xyunbtysKFCykqKmLNmjVHnQtZvnw5RUVF5OXlxdZVVFRw4MABsrKyYuu+//3vEwwGWb9+PWlpaZSVlfGDH/yAnTt38uijj5Kfn8/555/P9ddfT/fu3eN7g4GVK1cycuRIcnJyALj66qt58MEH2blzJ1dccQUFBQUsW7aM888/n9tuuw3gmOul5VAQyClj2zb33HMPF110EQCBQIBgMEh1dTVjxozh0ksv5dxzz+Waa65h6dKlmIOXwUpPT6/3OqmpqbG/LcuKPe7bDn3YW5YFgDEGj6f+P/njDbkc3u5LL73EH//4RyZMmMCoUaPIyspi586dR93H0aNHM3369NhycXExrVu3rvc4y7K49tpr+fOf/4zX6+Xaa6/Fsiy6du3K3//+dz788ENWr17NjTfeSEFBAZdccskx+/nt9r/NGEMkEiEvL49hw4axatUqVq5cyRNPPMHbb799zPWH3j9xPv1qSE6ZCy64gBdffJFQKIRt28yYMYP/+q//oqioiKqqKm699VYuueQSPvzww9hjGtpFF13EX/7yF0KhEJFI5JjVxLe9//77jBkzhuuuu44ePXqwbNkyotEoAG63m0gkEtvHN998k+LiYgBefvllrr/++qO+5pgxY1i2bBn/8z//w9VXXw3UBc7dd9/NBRdcwPTp07ngggvYsGFD3Ps3dOhQ3nrrLcrKygBYsmQJWVlZdO/enby8PD7//HOuvvpqHnjgASoqKigpKTnmemk5VBFIg6uurj5i2OSVV17h5ptv5qGHHmLMmDFEo1H69u3LXXfdRXp6OhdffDFXXHEFPp+P3r1706tXL4qKivD5fA3at6uvvppt27Zx1VVXkZ6eTpcuXUhLSzvh8yZPnszMmTNZvHgxAIMGDWLTpk0AnHfeedx+++088MADzJgxg5tuuonJkydjWRZ+v58nnngiVpUcrl27dvTr149IJEKHDh0AuOqqq1izZg0jR44kLS2N0047jfz8/KP26Y477uDuu++OLY8fP57p06dzww03cP3112PbNjk5OTz77LO4XC5uv/125syZw29+8xssy2Lq1Kl06dLlmOul5bDMsepqEQd6//33KS0tZfTo0QDMnj2blJSU2FCOSEukIJAWZe/evdx1113s27cP27bp06cPs2bNIjMzs7G7JtJoFAQiIi2cJotFRFo4BYGISAvXJH81VFtbS2FhIe3atcPtdjd2d0REmrxoNEpJSQkDBgyod65NPJpkEBQWFjJhwoTG7oaISLPz4osvcu655yb0nCYZBO3atQPqdqhjx46N3BsRkaZvz549TJgwIfb5mYgmGQSHhoM6duyoE1tERBJwMsPpmiwWEWnhFAQiIi2cgkBEpIVTEIiItHAKAhGRFk5BICLSwjkuCMY9+w8Wrz3yzlEiInJ0jguCT3eW88WeisbuhohIs+G4ILAs0IW1RUTi57wgAJQDIiLxc14QWJYqAhGRBDgvCACjmkBEJG6OCwI0RyAikhDHBYHV2B0QEWlmnBcEloVRSSAiEjcHBoF+NSQikgjnBQGaIxARSYTzgsCy9KshEZEEOC8IUEUgIpKIpNyz2LZtZs2axRdffIHP52P27Nl07949tn327Nl88sknZGRkAPDUU0+RmZnZIG1rjkBEJDFJCYKlS5cSCoVYtGgR69atY+7cuTz99NOx7Z999hnPPfccOTk5SWhdZxaLiCQiKUNDa9euZejQoQAMGjSIwsLC2DbbtikqKmLmzJnk5eWxePHiBm3bskA1gYhI/JJSEVRVVeH3+2PLbrebSCSCx+OhurqaiRMncuONNxKNRpk0aRIDBgygT58+DdK25ghERBKTlIrA7/cTCARiy7Zt4/HUZU5aWhqTJk0iLS0Nv9/Peeedx8aNGxusbV2GWkQkMUkJgsGDB7NixQoA1q1bR+/evWPbtm/fzvjx44lGo4TDYT755BP69+/fYG1b6OejIiKJSMrQ0IgRI1i1ahV5eXkYY5gzZw7z58+nW7duDB8+nFGjRjF27Fi8Xi+jR4/mjDPOaLC2XaoIREQSkpQgcLlcFBQU1FuXm5sb+/umm27ipptuSkbTWJaFrSAQEYmb404oA92PQEQkEY4LAkv3qhQRSYgjg0A5ICISP+cFAbofgYhIIpwXBKoIREQS4rwgQD8fFRFJhPOCwLJUEYiIJMB5QQCaIxARSYDjggDNEYiIJMRxQaCrUIuIJMZ5QaB7FouIJMR5QYB+NSQikgjnBYGuPioikhDnBYHuRyAikhDnBYEqAhGRhDguCEA/GhIRSYTjgsCyLFUEIiIJcF4QAKoJRETi57wg0ByBiEhCnBkEjd0JEZFmxHlBoBvTiIgkxHlBoIpARCQhzgsCNEcgIpII5wWBbkwjIpIQBwaBbkwjIpII5wUBGhoSEUmE84JA9yMQEUmI84IAVQQiIolwXhDozGIRkYQkJQhs22bmzJmMGzeO/Px8ioqKjvqYn/70p7z88ssN2rbuRyAikpikBMHSpUsJhUIsWrSIadOmMXfu3CMe85vf/Iby8vKGb1wVgYhIQpISBGvXrmXo0KEADBo0iMLCwnrb3377bSzL4sILL2zwti10ZrGISCKSEgRVVVX4/f7YstvtJhKJALBp0ybeeOMNbrnllmQ0jaUkEBFJiCcZL+r3+wkEArFl27bxeOqaev3119m7dy/XX389u3btwuv10rlz5warDurmCOwGeS0RkZYgKUEwePBg3n33XUaOHMm6devo3bt3bNsdd9wR+/vxxx+nbdu2DTpEpF8NiYgkJilBMGLECFatWkVeXh7GGObMmcP8+fPp1q0bw4cPT0aTMbr6qIhIYpISBC6Xi4KCgnrrcnNzj3jcf/zHfzR427ofgYhIYpx5Qlljd0JEpBlxXBCA5ghERBLhuCDQ/QhERBLjvCAAlQQiIglwXhBojkBEJCHOCwJUEIiIJMJ5QaAb04iIJMR5QYAqAhGRRDgvCHSJCRGRhDguCEA/HxURSYTjgqCuIlAUiIjEy3FB4LIauwciIs2L44LAwsJWRSAiEjfnBYEmi0VEEuLMIGjsToiINCPOCwLdj0BEJCGOCwJUEYiIJMRxQVB39dHG7oWISPPhvCDQ/QhERBLivCBAJ5SJiCTCeUGgOQIRkYQ4LwjQeQQiIolwXhDofgQiIglxXhCgikBEJBGOCwJ0iQkRkYQ4LggsdPlREZFEOC8IdD8CEZGEOC8I0M9HRUQSkZQgsG2bmTNnMm7cOPLz8ykqKqq3/cUXX+Saa67h2muv5d13323QtnUZahGRxHiS8aJLly4lFAqxaNEi1q1bx9y5c3n66acBKCsr46WXXuL1118nGAxy5ZVXcvHFF2NZDTO2b6Gfj4qIJCIpFcHatWsZOnQoAIMGDaKwsDC2LScnhz//+c94vV727dtHq1atGiwEQBWBiEiikhIEVVVV+P3+2LLb7SYSicSWPR4Pf/jDHxg3bhyXXXZZg7atS0yIiCQmKUHg9/sJBAKxZdu28Xjqj0JNnDiRlStX8tFHH7F69eoGbN1SRSAikoCkBMHgwYNZsWIFAOvWraN3796xbVu3bmXq1KkYY/B6vfh8PlyuhuuGpRsSiIgkJCmTxSNGjGDVqlXk5eVhjGHOnDnMnz+fbt26MXz4cPr06cO4ceOwLIuhQ4fyve99r8Ha1iUmREQSE1cQFBcXU1FRgdvt5ne/+x35+fn07dv3mI93uVwUFBTUW5ebmxv7e+rUqUydOvUku3x8miMQEUlMXGMyd955J/v27ePRRx9lyJAhzJkzJ9n9OmkuSzevFxFJRFxBEIlE+O53v0tFRQVXXnkltm0nu18nzQJs5YCISNziCoJwOMyvfvUrzj33XFavXk00Gk12v06apYpARCQhcQXB3Llz6dGjB1OmTKGsrIxf//rXye7Xv0QxICISv7iCoH379gwfPpyKigq2bdvWoD/3bGh1cwSN3QsRkeYjrk/022+/nc8++4x58+bh9XqZOXNmsvt10twuiGqSQEQkbnEFQUVFBZdccgl79+5lypQphEKhZPfrpLlcFlGVBCIicYt7svj555+nX79+bN68ud7lI5oat2VhqyIQEYlb3OcRlJaWcvPNN/Phhx8ya9asJHfr5LlVEYiIJCSuM4sHDx5MRUUFixYt4vTTT2fgwIHJ7tdJOzRZbIxp0Mtbi4g4VVwVwSOPPMKrr76Kx+Ph9ddfZ+7cucnu10lzu+o+/DVhLCISn7gqgo8++ohXXnkFgOuvv56xY8cmtVP/ilgQGJOcK+qJiDhM3JeYOHRZCdu2m/SQi+tg35rwVTBERJqUuL40X3nllfz4xz/m7LPP5tNPP2XkyJHJ7tdJcx+MNk0Yi4jE57hB8Mgjj8S+/Xfo0IF3332Xvn37UlZWdko6dzIOVQSaIxARic9xg6Bnz56xv3v06MGwYcOS3qF/1aE5Ap1LICISn+MGwZgxY05VPxrM4ZPFIiJyYk336nEn6ZvJYgWBiEg8HBcEqghERBLjvCDQZLGISEIcFwQul84jEBFJhOOCQOcRiIgkxnFBoPMIREQS47ggiJ1HoIpARCQuzgsCVQQiIglxXBC4dBlqEZGEOC4IDlUEGhoSEYmP84JAFYGISEIcFwQuTRaLiCQkKTfxsm2bWbNm8cUXX+Dz+Zg9ezbdu3ePbV+wYAFvvvkmABdddBFTp05tsLa/mSxusJcUEXG0pFQES5cuJRQKsWjRIqZNm1bvHsdfffUVf/nLX3jllVdYtGgR77//Phs3bmywtl2HTijT0JCISFySUhGsXbuWoUOHAjBo0CAKCwtj2zp27Mhzzz2H2+0G6m6DmZKS0mBta7JYRCQxSakIqqqq8Pv9sWW3200kEgHA6/WSk5ODMYaHHnqIfv360aNHjwZrW5PFIiKJSUoQ+P1+AoFAbNm2bTyeb4qPYDDI7bffTiAQ4P7772/Qtl26DLWISEKSEgSDBw9mxYoVAKxbt47evXvHthljuPnmmznzzDMpKCiIDRE1FLduTCMikpCkzBGMGDGCVatWkZeXhzGGOXPmMH/+fLp164Zt26xZs4ZQKMTKlSsBuO222zjnnHMapG0NDYmIJCYpQeByuSgoKKi3Ljc3N/b3+vXrk9FsXduaLBYRSYjjTijzuOuCIKKKQEQkLo4LAu/BO9OEdUaZiEhcHBcEPk/dLoUiCgIRkXg4Lgi8B4eGQlENDYmIxMNxQZBy8OeoqghEROLjuCA4NDSkOQIRkfg4LghiQ0OqCERE4uK4IPC4XbgsBYGISLwcFwRQ9xNSDQ2JiMTHkUHg87gIqiIQEYmLM4NAFYGISNycGQQel+YIRETi5NggUEUgIhIfRwaB1+0ipCAQEYmLI4PA59bQkIhIvBwZBF6PS9caEhGJkyODIMXtIhSJNnY3RESaBUcGgddjEVZFICISF0cGgeYIRETi58gg0CUmRETi58gg0AllIiLxc2wQ6FpDIiLxcWYQaGhIRCRuzgwCj84sFhGJlyODwOt2EdbQkIhIXBwZBKoIRETi58ggqPv5qMEYnVQmInIijgyCFE/dbqkqEBE5saQEgW3bzJw5k3HjxpGfn09RUdERjykrK+OHP/whwWCwwdv3ui1AN7AXEYlHUoJg6dKlhEIhFi1axLRp05g7d2697StXrmTy5Mns27cvGc3jc9ftlq43JCJyYkkJgrVr1zJ06FAABg0aRGFhYf1GXS7mz59PVlZWMprH53EDqghEROLhScaLVlVV4ff7Y8tut5tIJILHU9fckCFDktFsTLqvLgiqgpGktiMi4gRJqQj8fj+BQCC2bNt2LAROhTZ+HwBlgdApa1NEpLlKShAMHjyYFStWALBu3Tp69+6djGaOqU1GCgClVQ0/ES0i4jRJ+Zo+YsQIVq1aRV5eHsYY5syZw/z58+nWrRvDhw9PRpP1tD1YEZSqIhAROaGkBIHL5aKgoKDeutzc3CMet2zZsmQ0T3bGwSCoUhCIiJyII08o87pdtE7zUhrQ0JCIyIk4MgigbsJYFYGIyIk5NgjaZqSwT5PFIiIn5NggaOP3abJYRCQOjg2C9pkp7CmvxbZ1mQkRkeNxbBD069SKqmCEorLqxu6KiEiT5tgg6N+pNQAbdlc0ck9ERJo2xwbB6W0zACgqC5zgkSIiLZtjg8Cf4qFNho+vNDQkInJcjg0CgK456RSVKghERI7H0UHQvY2CQETkRJwdBDnpfF1eoxvUiIgch6ODILe9H9vApr2Vjd0VEZEmy9FBcO7pOQB8tL2skXsiItJ0OToIOmel0TkrTUEgInIcjg4CgO/3yGHV5lJqQtHG7oqISJPk+CC49jtdKK8Js+LLksbuiohIk+T4IBjULQuAZ9/b0sg9ERFpmhwfBOm+urtxfrLjAFtKqhq5NyIiTY/jgwDg5ZvOA+Av63Y3ck9ERJqeFhEEP8htw8VntuOlNTsauysiIk1OiwgCgIt6t6OkMshb67/mS51gJiIS42nsDpwq5/VsA8DNL34CwH9e0ovbfnhmY3ZJRKRJaDEVQd/TWrHwJ9+LLf922WbKq8ON2CMRkfreLvyaX731+Slvt8UEAdRVBb07+GPLZxe8wwdb9jVij0REvvHXf37N3zfsPeXttpihIQCv28U7v7iImlCUKQs/ZuWX+xj/uw+5pE97LujVlgt7t6NXe/+JX0hEJAn2VNTSoVXqKW+3RQXBIWk+Nwt/8n1eWbODu15dz7KNxSzbWAxAr/Z+LunTnq456Vzcux1dc9Ibubci0lLsKa/lez1yTnm7LTIIDsn7Xjeu/U4Xnlq+hceXfUk4athcXMXm4m9OPOvdwU9ZIMSUC3tSWhXiP4efgdftwjaGVK+b4opastJ9+DwtapRNRBpYKGJTXKmKoFF43C7+c/gZ/OfwM7Btw7qdByivDhOK2ty55FM27a0LhTlvbQTg2RVbY8/NbZfBlpIAAD/+Xjc6tkrFNoacDB8A63eVM+rsTnjdFv1Pa03rdC9FpQE6Z6XhcbswxmBZ1lH7dbxtIuI8n+0uJxw1nNW59SlvOylBYNs2s2bN4osvvsDn8zF79my6d+8e2/7HP/6RV155BY/Hw89//nOGDRuWjG4kzOWyGNwtO7Y8vE97osawtmg/O0qrqQpGeGfDXtZsq7us9aEQAHj5GCerLV67M/a3z+OK3S3N53HRPjOFnAwf5TVhLODiM9sTjEQJBKOsLdpPdoaXawd3oTocZf3Ocob0akvrNC/7q0MM6ppF6zQv5TVhstN9RG1DxDb0au9n14Ea2mT4sCworwnTzp8CQNQ2uF0WlmVRFYyQ6nHhcddVMtWhCBYWqV7XCQMoHLWxIPZaiQhGohgDqV43UBd4eypqOa11GpGoTW3Exp/iYU95LR1bn/pvRolIZli35C8CR9t32za4XCf/fpRUBmmXmdJgr3c0xhiAYx63/YEQtjGk+dyked2EojYpHjeBYIQ9FbWMeeoDAOcMDS1dupRQKMSiRYtYt24dc+fO5emnnwagpKSEhQsXsmTJEoLBIOPHj2fIkCH4fL5kdOVf4nG78ADn57bl/Ny6dT8d2jO2PRy18R78IK2oDeNxWZTXhNlTXstb679mS0mATlmplAVClFaFqA5F8bot+p7Wim37ApTXhGmT4aM2HOXL4ioWr91JqtdNRU1dRbLrQA2FuzbE2vtb4Z6T2g9/iodgJEo4avB5XHTLSY8Nf+W2y8AAWw+GWmaKh57tMjhQEyYQjHB2lyyKyqqpDUdJ8bho60/ho+1l2Kbufg9ndsxk94EaKmrC1ISjDOjcGsuyqA5GyM7wUVwZJCfdy8fb99M63cvO/TUA9O/UipwMH6s278M20D4zheLKIBk+Nz3aZVC4q4LMVA+2bfhejxzaZaawaW8VORk+2vp9uCyL2nCUXQdq8LhctPHXvY/FlUFKq0LktveT4nFhAbYxbC+tZmCX1nRolcq2kgA5fh/GgNdtsae8lrJAiGDEJmIbAsEI3dukk+p1UxuO4nW7qApG8Kd46JaTTkVtmI+372dHWTWjzu5EMByldZoXQ93rlVaFaJuZQjhi8/meCob0astnuyoo3F1Or3Z+BnRujTGGQCjKxj0V+NwuXJZFms/Ntn0BBnXN4p0Nezm3ezb7qoIEglG65qTRPjOVr8tr6NnWT2kgSPc2GUSiNgdqwhyoDpOR4qZ1mrfutbxudh2oIRy1WfnlvtgXnNPbZrDh6wra+VPonJXKvqoQRWUB9gfC9OmYSShq43ZZ9GibQcdWqeypqGXj15VkpXtxuSz8Pg9ZGV6iUcOBmjCt07zsKa8lHLVp40/h/3bsp2PrVLLSvLH3LzvDR3UwSofWqZQFgnyxp5KzOmfhT/WwfV8Ay4KsNC9l1WH+b8d+dh+oYUDn1pzXsw0llUHCUZsVm0o4u2sW7TNTMRiqg1Esq+7LSDhqU14TpneHTKpqI2wrDeBP8dAlO4095bXUhKOs3lr35W1Evw5s3xdgR1k1Z3fJYntpgKx078H/IzapXjdet0WbjBTSfG52lFbTrU06Po+L4ooggWAkNixcURuOPS4UibLuqwMYA239KdRGovjcLsJRm9JACH+KJ/ZvPzPFQ8fWqRSVVdMlK42t+775Qjl1WK96gXWqJCUI1q5dy9ChQwEYNGgQhYWFsW2ffvop55xzDj6fD5/PR7du3di4cSMDBw5MRleS6lAIALRK9QJ1F7k7rXUa5xxWWZyIMXXf5g+93qFvFsGITVkgRNQ21IajbNsX4LTWaeyvDvFx0X46tEohaht2H6ilXWYK5dUhKmojuF0WoYhN67S6PpUGQgc/IKAqGGFHWTW92vnZXhrAGDgtK5XsdB9f7q2kY+tUUjxuBnRKpzYc5av91URtQxt/CjnpXnYfqMU24HFZ1ISjbC2pImIbsjN8nJ7mZV9ViOKKWlqnedleGqBNRgr/LKumMhghx/9N2Odk+KioCXNWlyz++dUBymvqzukIhOoqIqj7D3WgOsSGryuo3WHTvU06W0uqKNwVpTYcJRCK0ve0TPYHatm4p4IOrVLxp3jYdaAmVhUZoCwQwmXBgeow+6qCZKd7CYSieF0WbpeFy2URtQ2tUr0YY+iSnc720gC2XReiNeEo6T43O8uq+ceWUqLGxCq7v/7zm+tXZad7OVATxud2kep1Y9uGztlpPPveVtJ9dR/SX5fXsnFP3ZntVcEIXbLT6NAqFa/bxY6yaoorgrzz2V46tk6lvCbM1pIA7TNTCEVs1mwrw7Jg094qAsEIXncpKV4XKR4XJZVBWqd5cbvqqj1j6v79HLLh6wp8Hhf/3HkAgN0Halj+RYhUr5tUr5uIbbO5pIpI1JDidbFmWxnVoSip3rp9aetPwbYN5TVhKmrDGAMRu+7fqc/tIivdy4GD5+UUlVZjm7rqM8XjIhw1hKM2wYiNx1UXeB9t3w9Al+w0APZVBakN27TLTKFXez/GwHMrt5KT4SMjxUNFbYT/23GA6lAEj8tFh9YpVNTUhXNGipsUj5s/rC4iO91HZTBCVpqX9zfv4+B/pZi/b9jLd7pnc35uGw4c/PJSvDeIZYExdcf7jA5+NnxdwbaDH9BrtpfRKtWDy2XROSuNr8qqsSymxe06AAAKuUlEQVSLNn4fG7+uxO2yyMnw0aFVKq1SvYSiNlmuuiDcvi/AgE6tSfe5sSxI87rJSvdRVBqg32mt8Kd42LovgM/t4ldXn8U13+kS9+dGQ0pKEFRVVeH3f/MzTLfbTSQSwePxUFVVRWZmZmxbRkYGVVUt+6qglmXhdVv1lqFu+KRTVlps/RkdvnnfLuzd7tR1sIk61vBJ8OC3saNtqw5FSPO6/6VhF2MMtqmrNDwHQyRqDCkeN6VVQfypHlI83wx9VdREaJ3uPeI1Dg//Y+1XIBgh1evGfYJhjAPVIVqleusNd0QPflAf67nhaN0H89HeC2MMpYEQOem+I4ZQDv+iAnVfiNwuC2NMveHHw0WiddVWiqfuuNSGo3hcVmxo0rZN3ft52PtxtONbG647tkcb1jnU9iGHhn8OX//txxwuFLGxrG++4B2q+A+v/L/9vtkH3+OGHmY61ZISBH6/n0Dgm3LHtm08Hs9RtwUCgXrBIBKvY32YH/oQPppDlyX/V9t1W+Cmrn2P24r9R2rjTznisd8OgUPrDw//b287JCMlvv5mpR85tHqi8DhaCB3eh7b+ow9RHP5F5dvrPcfYJ4/bxeGH5dvPdbksXNR/7tGO77efd7hv7++hD+fD1x/vPfn2L/8OvT/ffp8OX27uAXBIUn7zOHjwYFasWAHAunXr6N27d2zbwIEDWbt2LcFgkMrKSrZs2VJvu4iInFpJqQhGjBjBqlWryMvLwxjDnDlzmD9/Pt26dWP48OHk5+czfvx4jDH84he/ICXl1E+OiIhInaQEgcvloqCgoN663Nzc2N9jx45l7NixyWhaREQSpNNhRURaOAWBiEgLpyAQEWnhmuS1hqLRuhOK9uw5uTNpRURamkOfl4c+PxPRJIOgpKQEgAkTJjRyT0REmpeSkpJ613aLh2XMt0/Cbny1tbUUFhbSrl073O5jn0AiIiJ1otEoJSUlDBgwgNTUxC7Y2CSDQERETh1NFouItHBNco4gUcYYLrzwQk4//XSg7oqn06ZNq/eYJ554guXLl+PxeLjnnnuaxdVOt2zZwtixY/nggw+OOPt69uzZfPLJJ2RkZADw1FNPNYtrNh1vn5rqfSqOpbq6mmnTplFeXk5aWhq//vWvycmpfy355nac4tmn5nScKisrmT59OlVVVYTDYe666y7OOeeceo9pbsconn1K+BgZB9i+fbv52c9+dszthYWFJj8/39i2bXbt2mWuvvrqU9i7k1NZWWluuukmc95555na2tojtufl5ZnS0tJG6NnJO94+FRcXmx/96EcmGAyaioqK2N9N2fz5883jjz9ujDFmyZIl5oEHHjjiMc3tOJ1on5rbcXrsscfM/PnzjTHGbNmyxVx11VVHPKa5HaMT7dPJHCNHDA199tln7N27l/z8fG666Sa2bt1ab/vatWu54IILsCyLTp06EY1GKSsra6TenpgxhhkzZnDbbbeRlpZ2xHbbtikqKmLmzJnk5eWxePHiRuhlYk60T4ffpyIzMzN2n4qm7IYbbuDnP/85ALt376Zt27b1tjfH43SifWpux+mGG24gLy8PqJtM/XYV2lyP0fH26WSOUbMbGvrTn/7ECy+8UG/dzJkzmTJlCldccQUff/wx06dPZ8mSJbHtVVVVZGVlxZYzMjKorKw8ouRtDEfbn06dOjFy5Ej69Olz1OdUV1czceJEbrzxRqLRKJMmTWLAgAHHfPypdjL71NTvU3G0fZozZw4DBw5k0qRJbNq0ifnz59fb3hyP04n2qSkfp+PtT0lJCdOnT+eee+6pt705H6Nj7dNJHaPkFC+nVnV1db3SZ8iQIca27djyCy+8YP77v/87tjx69OgmXQpeeumlZuLEiWbixIlmwIABZvz48fW2RyIRU1lZGVt+6KGHzGuvvXaqu5mQE+3T0qVLzf333x9bvvnmm82nn356int58jZv3myGDx9eb11zPE6HO9o+NcfjtHHjRjNy5EizfPnyI7Y112N0vH06mWPkiCCYN29e7IP+888/N9ddd1297evXrzeTJk0y0WjU7Nq1y4waNaoxunlShg0bdsR4+ubNm82oUaNMJBIxoVDIjBs3zmzatKmRepi4o+3ToXHN2tpaU1FRYS677LKjzo00Jc8880zsQ2P37t3mhz/8Yb3tzfE4nWifmttx+vLLL81ll11mPv/886Nub47H6ET7dDLHqNkNDR3NlClTmD59Ou+99x5ut5tf/epXAMybN4/LL7+cgQMHcu655zJu3Dhs22bmzJmN3OOTc/g9HUaNGsXYsWPxer2MHj2aM844o7G7d1Ka830qrrnmGu68806WLFlCNBplzpw5QPM+TvHsU3M6To888gihUIgHH3wQqLtD4tNPP92sj1E8+5ToMdIJZSIiLZwjfjUkIiInT0EgItLCKQhERFo4BYGISAunIBARaeEUBNLsvfrqqzz88MNJee2pU6cm5XUP98UXX/DRRx8lvR2RY1EQiBzHE088kfQ23nnnHTZv3pz0dkSOxREnlIkcsnDhQt544w0sy2LkyJGxa+bMnTsX27apqKjgvvvuY/DgwQwbNoyePXvSs2dPKisr8fl87Nq1i+LiYubOnUv//v0ZMmQIq1atIj8/nz59+vDll19SVVXFY489RufOnXnyySdZunQpOTk51NTUcMstt/D9738/1p/8/Hyys7OpqKjg8ccf57777qOyspL9+/dz3XXXMXz4cF577TW8Xi/9+/entraWRx99FLfbTdeuXSkoKMDr9TbiOyotgSoCcYzNmzfz1ltv8dJLL/HSSy+xdOlStm7dyubNm7nzzjtZsGABN954I6+++ioAX3/9NQ8//DD33nsvUHdhvN///vfk5+ezaNGiI15/4MCBLFiwgCFDhvDmm2+yceNGVq5cyeLFi3nyySdj99r+tlGjRrFgwQJ27NjBlVdeyfPPP88zzzzDggUL6NChA2PGjOGGG27grLPOYsaMGTzxxBP84Q9/oEOHDrz22mvJe8NEDlJFII6xadMmdu/ezQ033ABAeXk5O3bsoH379jz11FOkpqYSCATw+/0AZGdnk52dHXt+3759AejYsSOffPLJEa/fr1+/2PZ9+/axZcsWzjrrLNxuN263mwEDBhy1Xz169ACgbdu2vPDCC7zzzjv4/X4ikUi9x5WVlVFcXMytt94K1N27e8iQIf/COyISHwWBOEbPnj3p1asXzz33HJZlsWDBAnr37s2///u/8/DDD5Obm8tvf/tbdu3aBYDLVb8gtiwrofZ69erFwoULsW2bSCTChg0bjvq4Q6/7/PPPM2jQIMaPH8/q1at57733Yttt2yY7O5uOHTvG7pD1v//7v6Snpyf6NogkTEEgjtGnTx9+8IMf8OMf/5hQKMTAgQPp0KED//Zv/8bNN99MmzZt6NixI/v372+Q9s4880wuuugixo4dS3Z2Nl6vF4/n2P+lhg0bxqxZs/jrX/9KVlYWbrebUCjEgAEDmDdvHrm5udx7771MmTIFYwwZGRnMmzevQfoqcjy66JzISSotLeXtt99mwoQJhEIhrrzySl544QU6derU2F0TSYgqApGTlJ2dTWFhIddccw2WZXHdddcpBKRZUkUgItLC6eejIiItnIJARKSFUxCIiLRwCgIRkRZOQSAi0sIpCEREWrj/B5/+vCE4UD27AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_callback.plot_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.1622776601683795e-05, 0.0031622776601683794)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10**-4.5, 10**-2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.log10(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clr import OneCycleLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_manager = OneCycleLR(train_gen.n_batches * train_gen.batch_size, train_gen.n_batches, train_gen.batch_size, \n",
    "                        max_lr=lr,\n",
    "                        end_percentage=0.1, scale_percentage=None,\n",
    "                        maximum_momentum=0.95, minimum_momentum=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s/S.Rasp/miniconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:55: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    }
   ],
   "source": [
    "model = fc_model(94, 65, [256]*9, 1e-3, 'mse', activation='LeakyReLU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.002, momentum=0.95, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer = optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s/S.Rasp/miniconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:55: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "27456/27456 [==============================] - 228s 8ms/step - loss: 0.0084 - rmse: 0.0805 - log_loss: -1.1461 - var_ratio: 0.2271 - mean_squared_error: 0.0084 - var_loss: 3.9136e-05\n",
      " - lr: 0.00001 - momentum: 0.95 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f189ac59a90>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_gen.return_generator(),   # This actually returns the generator\n",
    "    train_gen.n_batches,\n",
    "    epochs=1,\n",
    "    callbacks=[lr_manager]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "27456/27456 [==============================] - 229s 8ms/step - loss: 0.0071 - rmse: 0.0714 - log_loss: -1.2094 - var_ratio: 0.1970 - mean_squared_error: 0.0071 - var_loss: 4.2018e-05\n",
      " - lr: 0.00001 - momentum: 0.95 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f189aa81ba8>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_gen.return_generator(),   # This actually returns the generator\n",
    "    train_gen.n_batches,\n",
    "    epochs=1,\n",
    "    callbacks=[lr_manager]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 330G\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  54G Jan 10 16:22 32_col_engy_ess_1y_train_features.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  54G Jan 10 17:08 32_col_engy_ess_1y_train_shuffle_features.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  38G Jan 10 17:08 32_col_engy_ess_1y_train_shuffle_targets.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  38G Jan 10 16:32 32_col_engy_ess_1y_train_targets.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 5.3G Jan  8 12:49 32_col_engy_ess_3d_train_features.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  24K Jan  8 12:48 32_col_engy_ess_3d_train_norm.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 5.3G Jan  8 13:03 32_col_engy_ess_3d_train_shuffle_features.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 3.8G Jan  8 13:03 32_col_engy_ess_3d_train_shuffle_targets.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 3.8G Jan  8 12:50 32_col_engy_ess_3d_train_targets.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 1.4G Jan  9 11:17 32_col_engy_ess_3d_valid_features.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 952M Jan  9 11:17 32_col_engy_ess_3d_valid_targets.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 2.8G Jan 15 14:09 32_col_mp_3d_train_features.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  34K Jan 15 14:09 32_col_mp_3d_train_norm.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 2.3G Jan 15 14:10 32_col_mp_3d_train_targets.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  54G May  7  2018 fbp_engy_ess_ref_train_fullyear_shuffle_features.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  38G May  7  2018 fbp_engy_ess_ref_train_fullyear_shuffle_targets.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  25K Jul 27 10:17 fbp_engy_ess_ref_train_sample1_norm_big_fluxes2.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  25K Jul 24 17:59 fbp_engy_ess_ref_train_sample1_norm_big_fluxes.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  25K May  7  2018 fbp_engy_ess_ref_train_sample1_norm.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  25K Jul 26 18:54 fbp_engy_ess_ref_train_sample1_norm_small_fluxes2.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  25K Jul 25 10:57 fbp_engy_ess_ref_train_sample1_norm_small_fluxes.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  25K Apr 17  2018 fbp_engy_ess_train_fullyear_norm.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  25K Apr 20  2018 fbp_engy_ess_train_sample1_norm.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 8.8G Apr 17  2018 fbp_engy_ess_valid_fullyear_features.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 6.3G Apr 17  2018 fbp_engy_ess_valid_fullyear_targets.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 8.8G Apr 15  2018 fbp_engy_ess_valid_sample1_features.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 6.3G Apr 15  2018 fbp_engy_ess_valid_sample1_targets.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  24K Apr 18  2018 fullphy_fbp_train_fullyear_norm.nc\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh $DATADIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s/S.Rasp/miniconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:55: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-5236f5570719>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m94\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m65\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'LeakyReLU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     lr_finder = LRFinder(num_samples, batch_size, minimum_lr=0.002, maximum_lr=0.02,\n\u001b[0m\u001b[1;32m      4\u001b[0m                           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                           \u001b[0mvalidation_sample_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_samples' is not defined"
     ]
    }
   ],
   "source": [
    "for m in [0.9, 0.95, 0.99]:\n",
    "    model = fc_model(94, 65, [256]*9, 1e-3, 'mse', activation='LeakyReLU')\n",
    "    lr_finder = LRFinder(num_samples, batch_size, minimum_lr=0.002, maximum_lr=0.02,\n",
    "                          validation_data=(X_test, Y_test),\n",
    "                          validation_sample_rate=5,\n",
    "                          lr_scale='linear', save_dir='weights/momentum/momentum-%s/' % str(momentum),\n",
    "                          verbose=True)\n",
    "    optimizer = SGD(lr=0.002, momentum=momentum, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
