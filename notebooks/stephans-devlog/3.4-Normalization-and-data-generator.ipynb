{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to normalize?\n",
    "\n",
    "Now that we have the new data preprocessing, we can tackle the issue of normalization.\n",
    "\n",
    "For now these options should be available:\n",
    "- PCA\n",
    "- standard mean/std\n",
    "- max_rs (so essentially std by var and combinations thereof)\n",
    "\n",
    "I guess I should also look at how to then use that in a data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cbrain.imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '/local/S.Rasp/preprocessed_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 358G\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  18K Jan 24 14:34 000_norm.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 2.2G Jan 24 14:32 000_train.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 2.1G Jan 24 14:33 000_train_shuffle.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 2.2G Jan 24 14:33 000_valid.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 7.5G Jan 24 11:21 001_train.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 7.3G Jan 24 11:21 001_train_shuffle.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 6.8G Jan 24 11:25 001_valid.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  54G Jan 10 16:22 32_col_engy_ess_1y_train_features.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  54G Jan 10 17:08 32_col_engy_ess_1y_train_shuffle_features.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  38G Jan 10 17:08 32_col_engy_ess_1y_train_shuffle_targets.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  38G Jan 10 16:32 32_col_engy_ess_1y_train_targets.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 5.3G Jan  8 12:49 32_col_engy_ess_3d_train_features.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  24K Jan  8 12:48 32_col_engy_ess_3d_train_norm.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 5.3G Jan  8 13:03 32_col_engy_ess_3d_train_shuffle_features.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 3.8G Jan  8 13:03 32_col_engy_ess_3d_train_shuffle_targets.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 3.8G Jan  8 12:50 32_col_engy_ess_3d_train_targets.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 1.4G Jan  9 11:17 32_col_engy_ess_3d_valid_features.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 952M Jan  9 11:17 32_col_engy_ess_3d_valid_targets.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 2.8G Jan 15 14:09 32_col_mp_3d_train_features.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  34K Jan 15 14:09 32_col_mp_3d_train_norm.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 2.3G Jan 15 14:10 32_col_mp_3d_train_targets.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  54G May  7  2018 fbp_engy_ess_ref_train_fullyear_shuffle_features.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  38G May  7  2018 fbp_engy_ess_ref_train_fullyear_shuffle_targets.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  25K Jul 27 10:17 fbp_engy_ess_ref_train_sample1_norm_big_fluxes2.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  25K Jul 24  2018 fbp_engy_ess_ref_train_sample1_norm_big_fluxes.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  25K May  7  2018 fbp_engy_ess_ref_train_sample1_norm.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  25K Jul 26 18:54 fbp_engy_ess_ref_train_sample1_norm_small_fluxes2.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  25K Jul 25  2018 fbp_engy_ess_ref_train_sample1_norm_small_fluxes.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  25K Apr 17  2018 fbp_engy_ess_train_fullyear_norm.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  25K Apr 20  2018 fbp_engy_ess_train_sample1_norm.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 8.8G Apr 17  2018 fbp_engy_ess_valid_fullyear_features.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 6.3G Apr 17  2018 fbp_engy_ess_valid_fullyear_targets.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 8.8G Apr 15  2018 fbp_engy_ess_valid_sample1_features.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig 6.3G Apr 15  2018 fbp_engy_ess_valid_sample1_targets.nc\r\n",
      "-rw-r--r-- 1 S.Rasp ls-craig  24K Apr 18  2018 fullphy_fbp_train_fullyear_norm.nc\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh $DATADIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = xr.open_dataset(DATADIR + '000_train.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (sample: 3530752, var_names: 159)\n",
       "Coordinates:\n",
       "  * var_names  (var_names) object 'TBP' 'TBP' 'TBP' ... 'FLNT' 'FLNS' 'PRECT'\n",
       "    time       (sample) int64 ...\n",
       "    lat        (sample) float64 ...\n",
       "    lon        (sample) float64 ...\n",
       "Dimensions without coordinates: sample\n",
       "Data variables:\n",
       "    vars       (sample, var_names) float32 ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'var_names' (var_names: 159)>\n",
       "array(['TBP', 'TBP', 'TBP', 'TBP', 'TBP', 'TBP', 'TBP', 'TBP', 'TBP', 'TBP',\n",
       "       'TBP', 'TBP', 'TBP', 'TBP', 'TBP', 'TBP', 'TBP', 'TBP', 'TBP', 'TBP',\n",
       "       'TBP', 'TBP', 'TBP', 'TBP', 'TBP', 'TBP', 'TBP', 'TBP', 'TBP', 'TBP',\n",
       "       'QBP', 'QBP', 'QBP', 'QBP', 'QBP', 'QBP', 'QBP', 'QBP', 'QBP', 'QBP',\n",
       "       'QBP', 'QBP', 'QBP', 'QBP', 'QBP', 'QBP', 'QBP', 'QBP', 'QBP', 'QBP',\n",
       "       'QBP', 'QBP', 'QBP', 'QBP', 'QBP', 'QBP', 'QBP', 'QBP', 'QBP', 'QBP',\n",
       "       'VBP', 'VBP', 'VBP', 'VBP', 'VBP', 'VBP', 'VBP', 'VBP', 'VBP', 'VBP',\n",
       "       'VBP', 'VBP', 'VBP', 'VBP', 'VBP', 'VBP', 'VBP', 'VBP', 'VBP', 'VBP',\n",
       "       'VBP', 'VBP', 'VBP', 'VBP', 'VBP', 'VBP', 'VBP', 'VBP', 'VBP', 'VBP',\n",
       "       'PS', 'SOLIN', 'SHFLX', 'LHFLX', 'TPHYSTND', 'TPHYSTND', 'TPHYSTND',\n",
       "       'TPHYSTND', 'TPHYSTND', 'TPHYSTND', 'TPHYSTND', 'TPHYSTND', 'TPHYSTND',\n",
       "       'TPHYSTND', 'TPHYSTND', 'TPHYSTND', 'TPHYSTND', 'TPHYSTND', 'TPHYSTND',\n",
       "       'TPHYSTND', 'TPHYSTND', 'TPHYSTND', 'TPHYSTND', 'TPHYSTND', 'TPHYSTND',\n",
       "       'TPHYSTND', 'TPHYSTND', 'TPHYSTND', 'TPHYSTND', 'TPHYSTND', 'TPHYSTND',\n",
       "       'TPHYSTND', 'TPHYSTND', 'TPHYSTND', 'PHQ', 'PHQ', 'PHQ', 'PHQ', 'PHQ',\n",
       "       'PHQ', 'PHQ', 'PHQ', 'PHQ', 'PHQ', 'PHQ', 'PHQ', 'PHQ', 'PHQ', 'PHQ',\n",
       "       'PHQ', 'PHQ', 'PHQ', 'PHQ', 'PHQ', 'PHQ', 'PHQ', 'PHQ', 'PHQ', 'PHQ',\n",
       "       'PHQ', 'PHQ', 'PHQ', 'PHQ', 'PHQ', 'FSNT', 'FSNS', 'FLNT', 'FLNS',\n",
       "       'PRECT'], dtype=object)\n",
       "Coordinates:\n",
       "  * var_names  (var_names) object 'TBP' 'TBP' 'TBP' ... 'FLNT' 'FLNS' 'PRECT'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.var_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute standard normalization arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create a norm dataset\n",
    "# Mean, std, etc will have dimensions var_names\n",
    "norm_ds = xr.Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  ()\n",
       "Data variables:\n",
       "    *empty*"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = trn.vars.mean(dim='sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'vars' (var_names: 159)>\n",
       "array([ 2.289433e+02,  2.178566e+02,  1.987313e+02,  2.180804e+02,\n",
       "        2.155468e+02,  2.095004e+02,  2.065618e+02,  2.053417e+02,\n",
       "        2.047591e+02,  2.045300e+02,  2.049989e+02,  2.071436e+02,\n",
       "        2.086929e+02,  2.164163e+02,  2.216183e+02,  2.297919e+02,\n",
       "        2.385379e+02,  2.475247e+02,  2.542547e+02,  2.598487e+02,\n",
       "        2.625759e+02,  2.650574e+02,  2.691584e+02,  2.715526e+02,\n",
       "        2.732425e+02,  2.747398e+02,  2.764053e+02,  2.780224e+02,\n",
       "        2.805325e+02,  2.824123e+02,  1.700770e-06,  1.672413e-06,\n",
       "        1.382968e-06,  1.476775e-06,  1.424974e-06,  1.374307e-06,\n",
       "        1.372885e-06,  1.414201e-06,  1.548541e-06,  2.014882e-06,\n",
       "        3.756644e-06,  8.605848e-06,  1.979210e-05,  4.259874e-05,\n",
       "        8.878949e-05,  1.750205e-04,  3.230596e-04,  5.727612e-04,\n",
       "        9.818296e-04,  1.574560e-03,  2.375034e-03,  3.477780e-03,\n",
       "        4.781717e-03,  5.585611e-03,  6.171478e-03,  6.706584e-03,\n",
       "        7.143286e-03,  7.499316e-03,  7.747445e-03,  8.268956e-03,\n",
       "        1.580030e-01,  3.684007e-02,  2.337581e-02, -7.308686e-02,\n",
       "        1.765256e-02, -5.824275e-02,  1.116150e-02, -8.529415e-02,\n",
       "       -8.331335e-02, -1.369745e-01, -1.871017e-01, -3.021986e-01,\n",
       "       -4.204137e-01, -4.279659e-01, -2.308036e-01,  1.596970e-02,\n",
       "        1.381811e-01,  8.549015e-02,  2.086244e-03, -8.015581e-03,\n",
       "        1.217052e-02,  4.943033e-02,  1.206391e-01,  1.915368e-01,\n",
       "        2.124196e-01,  2.381628e-01,  2.726358e-01,  3.200150e-01,\n",
       "        3.435496e-01,  3.567290e-01,  9.816769e+04,  3.261490e+02,\n",
       "        1.362171e+01,  7.223798e+01,  8.143285e-07, -8.628160e-07,\n",
       "       -9.345628e-06,  1.539577e-05, -1.497087e-06, -5.951255e-08,\n",
       "       -1.118523e-06, -6.494299e-07,  2.864437e-07, -5.593091e-07,\n",
       "       -1.377916e-06, -2.560545e-06, -3.292262e-06, -4.263099e-06,\n",
       "       -4.526951e-06, -4.320892e-06, -3.657093e-06, -2.434830e-06,\n",
       "       -8.153958e-07,  1.529312e-07, -2.496700e-07, -2.187299e-06,\n",
       "       -3.048556e-06,  1.506614e-06,  3.735854e-06,  6.163471e-06,\n",
       "        7.062994e-06,  6.920664e-06,  5.767477e-06,  4.043348e-06,\n",
       "        0.000000e+00,  0.000000e+00, -2.438653e-13,  1.461535e-13,\n",
       "       -2.089846e-14, -2.997019e-14, -2.054538e-14, -3.705325e-14,\n",
       "       -6.615071e-13, -3.872032e-12, -1.752475e-11, -6.534000e-11,\n",
       "       -2.003594e-10, -4.907939e-10, -9.727725e-10, -1.536168e-09,\n",
       "       -2.127044e-09, -2.491958e-09, -2.746992e-09, -2.924505e-09,\n",
       "       -2.308703e-09,  3.110072e-10,  3.733740e-09,  3.110439e-09,\n",
       "        3.632456e-09,  3.947330e-09,  3.806885e-09,  4.742875e-09,\n",
       "        4.787473e-09,  4.925271e-09,  2.286378e+02,  1.611783e+02,\n",
       "        2.233854e+02,  5.197316e+01,  3.147634e-08], dtype=float32)\n",
       "Coordinates:\n",
       "  * var_names  (var_names) object 'TBP' 'TBP' 'TBP' ... 'FLNT' 'FLNS' 'PRECT'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_ds['mean'] = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (var_names: 159)\n",
       "Coordinates:\n",
       "  * var_names  (var_names) object 'TBP' 'TBP' 'TBP' ... 'FLNT' 'FLNS' 'PRECT'\n",
       "Data variables:\n",
       "    mean       (var_names) float32 228.94325 217.85664 ... 3.147634e-08"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for the by_var variables\n",
    "# First need to add a new coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = list(OrderedDict.fromkeys(trn.var_names.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_by_var = []\n",
    "std_by_var = []\n",
    "for var in var_list:\n",
    "    mean_by_var.append(trn.vars[:, trn.var_names == var].mean().values)\n",
    "    std_by_var.append(trn.vars[:, trn.var_names == var].std().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_ds['mean_by_var'] = xr.DataArray(mean_by_var, coords={'var_names_single': np.array(var_list).astype('object')}, dims=['var_names_single'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:           (var_names: 159, var_names_single: 14)\n",
       "Coordinates:\n",
       "  * var_names         (var_names) object 'TBP' 'TBP' 'TBP' ... 'FLNS' 'PRECT'\n",
       "  * var_names_single  (var_names_single) object 'TBP' 'QBP' ... 'FLNS' 'PRECT'\n",
       "Data variables:\n",
       "    mean              (var_names) float32 228.94325 217.85664 ... 3.147634e-08\n",
       "    mean_by_var       (var_names_single) float32 239.50552 ... 3.1559964e-08"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out output of script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = xr.open_dataset('/local/S.Rasp/preprocessed_data/000_norm.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:           (var_names: 159, var_names_single: 14)\n",
       "Coordinates:\n",
       "  * var_names         (var_names) object 'TBP' 'TBP' 'TBP' ... 'FLNS' 'PRECT'\n",
       "  * var_names_single  (var_names_single) object 'TBP' 'QBP' ... 'FLNS' 'PRECT'\n",
       "Data variables:\n",
       "    mean              (var_names) float32 ...\n",
       "    std               (var_names) float32 ...\n",
       "    min               (var_names) float32 ...\n",
       "    max               (var_names) float32 ...\n",
       "    std_by_var        (var_names_single) float32 ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a new data generator that normalizes\n",
    "\n",
    "What needs to happen here? \n",
    "\n",
    "1. Open dataset (h5py or xarray? do speed comparison)\n",
    "2. \n",
    "\n",
    "Use keras iterator base class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = ['TBP', 'QBP', 'VBP', 'PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "outputs = ['TPHYSTND', 'PHQ', 'FSNT', 'FSNS', 'FLNT', 'FLNS', 'PRECT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'var_names' (var_names: 159)>\n",
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False])\n",
       "Coordinates:\n",
       "  * var_names  (var_names) object 'TBP' 'TBP' 'TBP' ... 'FLNT' 'FLNS' 'PRECT'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_idxs = trn.var_names == inputs[0]\n",
    "input_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in inputs[1:]:\n",
    "    input_idxs = np.bitwise_or(input_idxs, trn.var_names == v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'var_names' (var_names: 159)>\n",
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False])\n",
       "Coordinates:\n",
       "  * var_names  (var_names) object 'TBP' 'TBP' 'TBP' ... 'FLNT' 'FLNS' 'PRECT'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = 1800.\n",
    "L_V = 2.501e6   # Latent heat of vaporization\n",
    "L_I = 3.337e5   # Latent heat of freezing\n",
    "L_S = L_V + L_I # Sublimation\n",
    "C_P = 1.00464e3 # Specific heat capacity of air at constant pressure\n",
    "G = 9.80616\n",
    "P0 = 1e5\n",
    "conversion_dict = {\n",
    "    'TPHYSTND': C_P,\n",
    "    'TPHY_NOKE': C_P,\n",
    "    'TPHYSTND_NORAD': C_P,\n",
    "    'PHQ': L_S,\n",
    "    'PHCLDLIQ' : L_S,\n",
    "    'PHCLDICE' : L_S,\n",
    "    'SPDT': C_P,\n",
    "    'SPDQ': L_V,\n",
    "    'QRL': C_P,\n",
    "    'QRS': C_P,\n",
    "    'PRECT': 1e3*24*3600 * 2e-2,\n",
    "    'TOT_PRECL': 24*3600 * 2e-2,\n",
    "    'TOT_PRECS': 24*3600 * 2e-2,\n",
    "    'PRECS': 1e3*24*3600 * 2e-2,\n",
    "    'FLUT': 1. * 1e-5,\n",
    "    'FSNT': 1. * 1e-3,\n",
    "    'FSDS': -1. * 1e-3,\n",
    "    'FSNS': -1. * 1e-3,\n",
    "    'FLNT': -1. * 1e-3,\n",
    "    'FLNS': 1. * 1e-3,\n",
    "    'QAP': L_S/DT,\n",
    "    'QCAP': L_S/DT,\n",
    "    'QIAP': L_S/DT\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    \"\"\"https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\"\"\"\n",
    "    def __init__(self, data_fn, input_vars, output_vars, \n",
    "                 norm_fn=None, input_transform=None, output_transform=None,\n",
    "                 batch_size=1024, shuffle=True):\n",
    "        # Just copy over the attributes\n",
    "        self.data_fn, self.norm_fn = data_fn, norm_fn\n",
    "        self.input_vars, self.output_vars = input_vars, output_vars\n",
    "        self.batch_size, self.shuffle = batch_size, shuffle\n",
    "        \n",
    "        # Open datasets\n",
    "        self.data_ds = xr.open_dataset(data_fn)\n",
    "        if not norm_fn is None: self.norm_ds = xr.open_dataset(norm_fn)\n",
    "        \n",
    "        # Compute number of samples and batches\n",
    "        self.n_samples = self.data_ds.vars.shape[0]\n",
    "        self.n_batches = int(np.floor(self.n_samples) / self.batch_size)\n",
    "        \n",
    "        # Get input and output variable indices\n",
    "        self.input_idxs = return_var_idxs(self.data_ds, input_vars)\n",
    "        self.output_idxs = return_var_idxs(self.data_ds, output_vars)\n",
    "        self.n_inputs, self.n_outputs = int(self.input_idxs.sum()), int(self.output_idxs.sum())\n",
    "        \n",
    "        \n",
    "        # Initialize input and output normalizers/transformers\n",
    "        if input_transform is None: self.input_transform = Normalizer()\n",
    "        elif input_transform == 'standard': self.input_transform = StandardNormalizer(self.norm_ds, input_vars)\n",
    "        elif input_transform == 'max_rs': self.input_transform = MaxRSNormalizer(self.norm_ds, input_vars)\n",
    "        else: self.input_transform = input_transform   # Assume an initialized normalizer is passed\n",
    "            \n",
    "        if output_transform is None: self.output_transform = Normalizer()\n",
    "        elif type(output_transform) is dict: \n",
    "            self.output_transform = DictNormalizer(self.norm_ds, output_vars, output_transform)\n",
    "        else: self.output_transform = output_transform   # Assume an initialized normalizer is passed\n",
    "            \n",
    "        # Now close the xarray file and load it as an h5 file instead\n",
    "        # This significantly speeds up the reading of the data... \n",
    "        self.data_ds.close()\n",
    "        self.data_ds = h5py.File(data_fn, 'r')\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_batches\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Compute start and end indices for batch\n",
    "        start_idx = index * self.batch_size\n",
    "        end_idx = start_idx + self.batch_size\n",
    "        \n",
    "        # Grab batch from data\n",
    "        batch = self.data_ds['vars'][start_idx:end_idx]\n",
    "        \n",
    "        # Split into inputs and outputs\n",
    "        X = batch[:, self.input_idxs]\n",
    "        Y = batch[:, self.output_idxs]\n",
    "        \n",
    "        # Normalize\n",
    "        X = self.input_transform.transform(X)\n",
    "        Y = self.output_transform.transform(Y)\n",
    "        \n",
    "        return X, Y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(self.n_batches)\n",
    "        if self.shuffle: np.random.shuffle(indices)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "??return_var_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(x):\n",
    "        return x\n",
    "\n",
    "class StandardNormalizer(Normalizer):\n",
    "    def __init__(self, norm_ds, var_list):\n",
    "        var_idxs = return_var_idxs(norm_ds, var_list)\n",
    "        self.mean = norm_ds['mean'].values[var_idxs]\n",
    "        self.std = norm_ds['std'].values[var_idxs]\n",
    "        \n",
    "    def transform(self, x):\n",
    "        return (x - self.mean) / self.std\n",
    "    \n",
    "class MaxRSNormalizer(Normalizer):\n",
    "    def __init__(self, norm_ds, var_list):\n",
    "        var_idxs = return_var_idxs(norm_ds, var_list)\n",
    "        self.mean = norm_ds['mean'].values[var_idxs]\n",
    "        rang = norm_ds['max'][var_idxs] - norm_ds['min'][var_idxs]\n",
    "        std_by_var = rang.copy()\n",
    "        for v in var_list:\n",
    "            std_by_var[std_by_var.var_names == v] = norm_ds['std_by_var'][norm_ds.var_names_single == v]\n",
    "        self.maxrs = np.maximum(rang, std_by_var).values\n",
    "        \n",
    "    def transform(self, x):\n",
    "        return (x - self.mean) / self.maxrs\n",
    "\n",
    "class DictNormalizer(Normalizer):\n",
    "    def __init__(self, norm_ds, var_list, dic):\n",
    "        var_idxs = return_var_idxs(norm_ds, var_list)\n",
    "        var_names = norm_ds.var_names[var_idxs].copy()\n",
    "        scale = np.zeros(var_names.shape).astype('float32')\n",
    "        for i, v in enumerate(list(var_names.values)):\n",
    "            scale[i] = dic[v]\n",
    "        self.scale = scale\n",
    "        \n",
    "    def transform(self, x):\n",
    "        return x * self.scale\n",
    "    \n",
    "    def inverse_transform(self, x):\n",
    "        return x / self.scale\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = DataGenerator(DATADIR + '000_train.nc', inputs, outputs, DATADIR + '000_norm.nc', input_transform='max_rs', \n",
    "                    output_transform=conversion_dict, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 65)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.n_inputs, gen.n_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'var_names' ()>\n",
       "array(94)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.input_idxs.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'var_names' (var_names: 159)>\n",
       "array([False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True])\n",
       "Coordinates:\n",
       "  * var_names  (var_names) object 'TBP' 'TBP' 'TBP' ... 'FLNT' 'FLNS' 'PRECT'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.output_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prof():\n",
    "    for i in range(100):\n",
    "        gen.__getitem__(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prof2():\n",
    "    for i in range(100):\n",
    "        gen2.__getitem__(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f gen2.__getitem__ prof2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much much fast using h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a test neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(gen.n_inputs,))\n",
    "x = Dense(128, activation='elu')(inp)\n",
    "x = Dense(gen.n_outputs)(x)\n",
    "model = tf.keras.models.Model(inp, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 94)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               12160     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 65)                8385      \n",
      "=================================================================\n",
      "Total params: 20,545\n",
      "Trainable params: 20,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3448/3448 [==============================] - 20s 6ms/step - loss: 0.0028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fca2845e780>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3448/3448 [==============================] - 17s 5ms/step - loss: 0.0028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fca2845e9b0>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(gen, use_multiprocessing=True, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3448/3448 [==============================] - 17s 5ms/step - loss: 0.0027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fca2845e4a8>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(gen, use_multiprocessing=True, workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7307177 ,  0.7395819 ,  1.0879064 , ..., -0.76381034,\n",
       "        -0.8114089 ,  0.37327787],\n",
       "       [ 0.730547  ,  0.7398344 ,  1.0878801 , ..., -0.7627074 ,\n",
       "        -0.8103464 ,  0.37378797],\n",
       "       [ 0.7303852 ,  0.74008775,  1.0880003 , ..., -0.7616356 ,\n",
       "        -0.80933475,  0.37457484],\n",
       "       ...,\n",
       "       [ 0.7090288 ,  0.7769988 ,  1.2447591 , ..., -0.74259055,\n",
       "        -0.8132322 , -0.7393508 ],\n",
       "       [ 0.70754194,  0.7722932 ,  1.2415448 , ..., -0.71721876,\n",
       "        -0.78374076, -0.7425638 ],\n",
       "       [ 0.71111214,  0.76260144,  1.2401541 , ..., -0.7136309 ,\n",
       "        -0.77401555, -0.74302304]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3530752, 159)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.vars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = ['TBP', 'SOLIN']\n",
    "outputs = ['TPHYSTND', 'PRECT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (sample: 3530752, var_names: 159)\n",
       "Coordinates:\n",
       "  * var_names  (var_names) object 'TBP' 'TBP' 'TBP' ... 'FLNT' 'FLNS' 'PRECT'\n",
       "    time       (sample) int64 ...\n",
       "    lat        (sample) float64 ...\n",
       "    lon        (sample) float64 ...\n",
       "Dimensions without coordinates: sample\n",
       "Data variables:\n",
       "    vars       (sample, var_names) float32 ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:           (var_names: 159, var_names_single: 14)\n",
       "Coordinates:\n",
       "  * var_names         (var_names) object 'TBP' 'TBP' 'TBP' ... 'FLNS' 'PRECT'\n",
       "  * var_names_single  (var_names_single) object 'TBP' 'QBP' ... 'FLNS' 'PRECT'\n",
       "Data variables:\n",
       "    mean              (var_names) float32 ...\n",
       "    std               (var_names) float32 ...\n",
       "    min               (var_names) float32 ...\n",
       "    max               (var_names) float32 ...\n",
       "    std_by_var        (var_names_single) float32 ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
