{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New model class and loss using tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cbrain.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '/local/S.Rasp/preprocessed_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/local/S.Rasp/preprocessed_data//000_norm.nc\r\n",
      "/local/S.Rasp/preprocessed_data//000_train.nc\r\n",
      "/local/S.Rasp/preprocessed_data//000_train_shuffle.nc\r\n",
      "/local/S.Rasp/preprocessed_data//000_valid.nc\r\n"
     ]
    }
   ],
   "source": [
    "!ls $DATADIR/000*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The training script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cbrain.data_generator import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = ['TBP', 'QBP', 'VBP', 'PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "outputs = ['TPHYSTND', 'PHQ', 'FSNT', 'FSNS', 'FLNT', 'FLNS', 'PRECT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cbrain.normalization import conversion_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen.data_ds.close(); valid_gen.data_ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(\n",
    "    DATADIR + '000_train.nc', inputs, outputs, DATADIR + '000_norm.nc', input_transform='max_rs', \n",
    "    output_transform=conversion_dict, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': array([ 2.2894325e+02,  2.1785664e+02,  1.9873132e+02,  2.1808038e+02,\n",
       "         2.1554680e+02,  2.0950041e+02,  2.0656183e+02,  2.0534174e+02,\n",
       "         2.0475914e+02,  2.0452998e+02,  2.0499893e+02,  2.0714363e+02,\n",
       "         2.0869292e+02,  2.1641628e+02,  2.2161829e+02,  2.2979195e+02,\n",
       "         2.3853790e+02,  2.4752470e+02,  2.5425475e+02,  2.5984869e+02,\n",
       "         2.6257587e+02,  2.6505743e+02,  2.6915845e+02,  2.7155261e+02,\n",
       "         2.7324252e+02,  2.7473978e+02,  2.7640533e+02,  2.7802243e+02,\n",
       "         2.8053253e+02,  2.8241229e+02,  1.7007696e-06,  1.6724131e-06,\n",
       "         1.3829675e-06,  1.4767750e-06,  1.4249738e-06,  1.3743067e-06,\n",
       "         1.3728851e-06,  1.4142012e-06,  1.5485415e-06,  2.0148816e-06,\n",
       "         3.7566444e-06,  8.6058481e-06,  1.9792098e-05,  4.2598738e-05,\n",
       "         8.8789493e-05,  1.7502054e-04,  3.2305956e-04,  5.7276123e-04,\n",
       "         9.8182959e-04,  1.5745604e-03,  2.3750337e-03,  3.4777804e-03,\n",
       "         4.7817174e-03,  5.5856109e-03,  6.1714784e-03,  6.7065842e-03,\n",
       "         7.1432861e-03,  7.4993158e-03,  7.7474448e-03,  8.2689561e-03,\n",
       "         1.5800297e-01,  3.6840070e-02,  2.3375807e-02, -7.3086858e-02,\n",
       "         1.7652560e-02, -5.8242749e-02,  1.1161497e-02, -8.5294150e-02,\n",
       "        -8.3313346e-02, -1.3697448e-01, -1.8710166e-01, -3.0219856e-01,\n",
       "        -4.2041367e-01, -4.2796594e-01, -2.3080356e-01,  1.5969705e-02,\n",
       "         1.3818112e-01,  8.5490152e-02,  2.0862436e-03, -8.0155814e-03,\n",
       "         1.2170521e-02,  4.9430329e-02,  1.2063910e-01,  1.9153681e-01,\n",
       "         2.1241958e-01,  2.3816276e-01,  2.7263579e-01,  3.2001504e-01,\n",
       "         3.4354961e-01,  3.5672897e-01,  9.8167688e+04,  3.2614905e+02,\n",
       "         1.3621709e+01,  7.2237976e+01], dtype=float32),\n",
       " 'maxrs': array([8.47328796e+01, 7.03986206e+01, 6.58636475e+01, 6.10176697e+01,\n",
       "        5.79564667e+01, 4.93826752e+01, 5.62059479e+01, 5.18293762e+01,\n",
       "        4.46331482e+01, 4.17065430e+01, 4.07757721e+01, 3.65075531e+01,\n",
       "        3.71367798e+01, 3.85567322e+01, 4.28357086e+01, 4.76646118e+01,\n",
       "        4.99546204e+01, 4.81739960e+01, 4.57843475e+01, 4.34865265e+01,\n",
       "        4.21294556e+01, 4.09424744e+01, 3.66290588e+01, 3.51396179e+01,\n",
       "        3.43227844e+01, 3.36757507e+01, 3.29892883e+01, 3.29949646e+01,\n",
       "        3.42889099e+01, 3.60921631e+01, 4.01672861e-03, 4.01672861e-03,\n",
       "        4.01672861e-03, 4.01672861e-03, 4.01672861e-03, 4.01672861e-03,\n",
       "        4.01672861e-03, 4.01672861e-03, 4.01672861e-03, 4.01672861e-03,\n",
       "        4.01672861e-03, 4.01672861e-03, 4.01672861e-03, 4.01672861e-03,\n",
       "        4.01672861e-03, 4.01672861e-03, 4.74067871e-03, 6.54950272e-03,\n",
       "        8.39518849e-03, 1.02979690e-02, 1.23483194e-02, 1.45902038e-02,\n",
       "        1.60121452e-02, 1.75313875e-02, 1.86206978e-02, 1.93642396e-02,\n",
       "        1.94971208e-02, 1.94366258e-02, 2.01250166e-02, 2.25927513e-02,\n",
       "        2.39699341e+02, 1.67855682e+02, 1.42375839e+02, 1.16757393e+02,\n",
       "        9.20466614e+01, 7.85979309e+01, 7.29305496e+01, 7.28949738e+01,\n",
       "        7.76536407e+01, 9.38812408e+01, 1.17532028e+02, 1.28846603e+02,\n",
       "        1.30296326e+02, 1.28804199e+02, 1.31027466e+02, 1.21826881e+02,\n",
       "        1.12758545e+02, 9.98528748e+01, 8.38654785e+01, 7.03967285e+01,\n",
       "        6.03937607e+01, 5.88651085e+01, 6.21920929e+01, 6.38531723e+01,\n",
       "        6.79754562e+01, 7.35899506e+01, 7.22511520e+01, 6.53119736e+01,\n",
       "        6.01853027e+01, 5.59871216e+01, 1.31140156e+04, 1.41064417e+03,\n",
       "        2.36730133e+02, 7.59204529e+02], dtype=float32)}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen.input_transform.transform_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen = DataGenerator(\n",
    "    DATADIR + '000_valid.nc', inputs, outputs, DATADIR + '000_norm.nc', input_transform='max_rs', \n",
    "    output_transform=conversion_dict, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_layer(act):\n",
    "    \"\"\"Helper function to return regular and advanced activation layers\"\"\"\n",
    "    return Activation(act) if act in tf.keras.activations.__dict__.keys() else tf.keras.layers.__dict__[act]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.layers.core.Activation"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_model(input_shape, output_shape, hidden_layers, activation):\n",
    "    \n",
    "    inp = Input(shape=(input_shape,))\n",
    "    \n",
    "    # First hidden layer\n",
    "    x = Dense(hidden_layers[0])(inp)\n",
    "    x = act_layer(activation)(x)\n",
    "    \n",
    "    # Remaining hidden layers\n",
    "    for h in hidden_layers[1:]:\n",
    "        x = Dense(h)(x)\n",
    "        x = act_layer(activation)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    out = Dense(output_shape)(x)\n",
    "    \n",
    "    return tf.keras.models.Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fc_model(train_gen.n_inputs, train_gen.n_outputs, [128, 128], 'LeakyReLU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 94)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               12160     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 65)                8385      \n",
      "=================================================================\n",
      "Total params: 37,057\n",
      "Trainable params: 37,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(tf.keras.optimizers.Adam(0.1), loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRUpdate(object):\n",
    "    def __init__(self, init_lr, step, divide):\n",
    "        # From goo.gl/GXQaK6\n",
    "        self.init_lr = init_lr\n",
    "        self.step = step\n",
    "        self.drop = 1./divide\n",
    "        \n",
    "    def __call__(self, epoch):\n",
    "        lr = self.init_lr * np.power(self.drop, np.floor((epoch)/self.step))\n",
    "        print(f'Learning rate = {lr}')\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_update = LRUpdate(0.001, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate = 4.000000000000001e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.000000000000001e-05"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_update(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate = 0.001\n",
      "Epoch 1/2\n",
      " 294/3448 [=>............................] - ETA: 23s - loss: 0.0025"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-623afa493ef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_update\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2175\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         outs = model.train_on_batch(\n\u001b[0;32m--> 176\u001b[0;31m             x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1939\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1940\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_gen, epochs=2, validation_data=valid_gen, callbacks=[LearningRateScheduler(lr_update)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model file and text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/local/S.Rasp/tmp/000_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('/local/S.Rasp/tmp/000_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cbrain.save_weights import save2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "save2txt('/local/S.Rasp/tmp/000_model_weights.h5', '/local/S.Rasp/tmp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000_model.h5\t      annos_ret_valid.csv  layer3_kernel.txt\r\n",
      "000_model_weights.h5  clas_full.csv\t   q2_1-32.png\r\n",
      "1-imbalance.png       clas_prac.csv\t   q2_2-32.png\r\n",
      "1.pkl\t\t      clas_ret.csv\t   sample_SPCAM.nc\r\n",
      "2-imbalance.png       layer1_bias.txt\t   scatter_fqt_q2_1-32.png\r\n",
      "2.pkl\t\t      layer1_kernel.txt    scatter_fqt_q2_2-32.png\r\n",
      "annos_full.csv\t      layer2_bias.txt\t   test.nc\r\n",
      "annos_prac.csv\t      layer2_kernel.txt    test_shuffle.nc\r\n",
      "annos_ret_train.csv   layer3_bias.txt\t   test.tfrecords\r\n"
     ]
    }
   ],
   "source": [
    "!ls /local/S.Rasp/tmp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buuuut saving the normalization files will be a little more involved. Actually, it might be really easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt = '%.6e'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_norm(input_transform, output_transform, save_dir):\n",
    "    for name, arr in input_transform.transform_arrays.items():\n",
    "        np.savetxt(save_dir + f'/inp_{name}.txt', arr.reshape(1, -1), fmt=fmt, delimiter=',')\n",
    "    for name, arr in output_transform.transform_arrays.items():\n",
    "        np.savetxt(save_dir + f'/out_{name}.txt', arr.reshape(1, -1), fmt=fmt, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_norm(train_gen.input_transform, train_gen.output_transform, '/local/S.Rasp/tmp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000_model.h5\t      clas_full.csv\t layer3_kernel.txt\r\n",
      "000_model_weights.h5  clas_prac.csv\t out_scale.txt\r\n",
      "1-imbalance.png       clas_ret.csv\t q2_1-32.png\r\n",
      "1.pkl\t\t      inp_maxrs.txt\t q2_2-32.png\r\n",
      "2-imbalance.png       inp_mean.txt\t sample_SPCAM.nc\r\n",
      "2.pkl\t\t      layer1_bias.txt\t scatter_fqt_q2_1-32.png\r\n",
      "annos_full.csv\t      layer1_kernel.txt  scatter_fqt_q2_2-32.png\r\n",
      "annos_prac.csv\t      layer2_bias.txt\t test.nc\r\n",
      "annos_ret_train.csv   layer2_kernel.txt  test_shuffle.nc\r\n",
      "annos_ret_valid.csv   layer3_bias.txt\t test.tfrecords\r\n"
     ]
    }
   ],
   "source": [
    "!ls /local/S.Rasp/tmp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some debugging for the shuffling script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
