{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cbrain.imports import *\n",
    "from cbrain.data_generator import *\n",
    "from cbrain.cam_constants import *\n",
    "from cbrain.losses import *\n",
    "from cbrain.utils import limit_mem\n",
    "from cbrain.layers import *\n",
    "from cbrain.data_generator import DataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow import math as tfm\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from cbrain.model_diagnostics import ModelDiagnostics\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imag\n",
    "import scipy.integrate as sin\n",
    "#import cartopy.crs as ccrs\n",
    "import matplotlib.ticker as mticker\n",
    "#from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import seaborn as sns\n",
    "from cbrain.imports import *\n",
    "from cbrain.utils import *\n",
    "from cbrain.normalization import *\n",
    "import h5py\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from cbrain.climate_invariant import *\n",
    "import yaml\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load coordinates (just pick any file from the climate model run)\n",
    "coor = xr.open_dataset(\"/DFS-L/DATA/pritchard/tbeucler/SPCAM/sp8fbp_minus4k/sp8fbp_minus4k.cam2.h2.0000-01-01-00000.nc\",\\\n",
    "                    decode_times=False)\n",
    "lat = coor.lat; lon = coor.lon; lev = coor.lev;\n",
    "coor.close();\n",
    "path = '/export/nfs0home/ankitesg/CBrain_project/CBRAIN-CAM/cbrain/'\n",
    "path_hyam = 'hyam_hybm.pkl'\n",
    "\n",
    "hf = open(path+path_hyam,'rb')\n",
    "hyam,hybm = pickle.load(hf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_dict = load_pickle('/export/nfs0home/ankitesg/CBrain_project/CBRAIN-CAM/nn_config/scale_dicts/009_Wm2_scaling.pkl')\n",
    "scale_dict['RH'] = 0.01*L_S/G, # Arbitrary 0.1 factor as specific humidity is generally below 2%\n",
    "\n",
    "in_vars_RH = ['RH','TBP','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "out_vars_RH = ['PHQ','TPHYSTND','FSNT', 'FSNS', 'FLNT', 'FLNS']\n",
    "\n",
    "TRAINFILE_RH = 'CI_RH_M4K_NORM_train_shuffle.nc'\n",
    "NORMFILE_RH = 'CI_RH_M4K_NORM_norm.nc'\n",
    "VALIDFILE_RH = 'CI_RH_M4K_NORM_valid.nc'\n",
    "BASE_DIR = '/DFS-L/DATA/pritchard/ankitesg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_RH = DataGenerator(\n",
    "    data_fn = f\"{BASE_DIR}data/{TRAINFILE_RH}\",\n",
    "    input_vars = in_vars_RH,\n",
    "    output_vars = out_vars_RH,\n",
    "    norm_fn = f\"{BASE_DIR}data/{NORMFILE_RH}\",\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    "    normalize_flag=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['QBP','TfromNSV2','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "out_vars = ['PHQ','TPHYSTND','FSNT', 'FSNS', 'FLNT', 'FLNS']\n",
    "\n",
    "TRAINFILE_TNS = 'CI_TNSV2_M4K_NORM_train_shuffle.nc'\n",
    "NORMFILE_TNS = 'CI_TNSV2_M4K_NORM_norm.nc'\n",
    "VALIDFILE_TNS = 'CI_TNSV2_M4K_NORM_valid.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_TNS = DataGenerator(\n",
    "    data_fn = f\"{BASE_DIR}data/{TRAINFILE_TNS}\",\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = f\"{BASE_DIR}data/{NORMFILE_TNS}\",\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    "    normalize_flag=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['QBP','TBP','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "out_vars = ['PHQ','TPHYSTND','FSNT', 'FSNS', 'FLNT', 'FLNS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this won't be used just to show we can use it overall\n",
    "TRAINFILE = 'CI_SP_M4K_train_shuffle.nc'\n",
    "NORMFILE = 'CI_SP_M4K_NORM_norm.nc'\n",
    "VALIDFILE = 'CI_SP_M4K_valid.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_m4k = DataGeneratorClimInv(\n",
    "    data_fn = f\"{BASE_DIR}data/{TRAINFILE}\",\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = f\"{BASE_DIR}data/{NORMFILE}\",\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    "    normalize_flag=True,\n",
    "    lev=lev,\n",
    "    hyam=hyam,hybm=hybm,\n",
    "    inp_subRH=train_gen_RH.input_transform.sub, inp_divRH=train_gen_RH.input_transform.div,\n",
    "    inp_subTNS=train_gen_TNS.input_transform.sub,inp_divTNS=train_gen_TNS.input_transform.div,\n",
    "    rh_trans = True,t2tns_trans=True,\n",
    "    lhflx_trans=True,\n",
    "    scaling=False,\n",
    "    interpolate=True,\n",
    "    exp={\"LHFLX\":True}\n",
    ")\n",
    "\n",
    "valid_gen_m4k = DataGeneratorClimInv(\n",
    "    data_fn = f\"{BASE_DIR}data/{VALIDFILE}\",\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = f\"{BASE_DIR}data/{NORMFILE}\",\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    "    normalize_flag=True,\n",
    "    lev=lev,\n",
    "    hyam=hyam,hybm=hybm,\n",
    "    inp_subRH=train_gen_RH.input_transform.sub, inp_divRH=train_gen_RH.input_transform.div,\n",
    "    inp_subTNS=train_gen_TNS.input_transform.sub,inp_divTNS=train_gen_TNS.input_transform.div,\n",
    "    rh_trans = True,t2tns_trans=True,\n",
    "    lhflx_trans=True,\n",
    "    scaling=False,\n",
    "    interpolate=True,\n",
    "        exp={\"LHFLX\":True}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this won't be used just to show we can use it overall\n",
    "TRAINFILE = 'CI_SP_P4K_train_shuffle.nc'\n",
    "NORMFILE = 'CI_SP_P4K_NORM_norm.nc'\n",
    "VALIDFILE = 'CI_SP_P4K_valid.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_p4k = DataGeneratorClimInv(\n",
    "    data_fn = f\"{BASE_DIR}data/{TRAINFILE}\",\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = f\"{BASE_DIR}data/{NORMFILE}\",\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    "    normalize_flag=True,\n",
    "    lev=lev,\n",
    "    hyam=hyam,hybm=hybm,\n",
    "    inp_subRH=train_gen_RH.input_transform.sub, inp_divRH=train_gen_RH.input_transform.div,\n",
    "    inp_subTNS=train_gen_TNS.input_transform.sub,inp_divTNS=train_gen_TNS.input_transform.div,\n",
    "    rh_trans = True,t2tns_trans=True,\n",
    "    lhflx_trans=True,\n",
    "    scaling=False,\n",
    "    interpolate=True,\n",
    "    exp={\"LHFLX\":True}\n",
    ")\n",
    "\n",
    "valid_gen_p4k = DataGeneratorClimInv(\n",
    "    data_fn = f\"{BASE_DIR}data/{VALIDFILE}\",\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = f\"{BASE_DIR}data/{NORMFILE}\",\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    "    normalize_flag=True,\n",
    "    lev=lev,\n",
    "    hyam=hyam,hybm=hybm,\n",
    "    inp_subRH=train_gen_RH.input_transform.sub, inp_divRH=train_gen_RH.input_transform.div,\n",
    "    inp_subTNS=train_gen_TNS.input_transform.sub,inp_divTNS=train_gen_TNS.input_transform.div,\n",
    "    rh_trans = True,t2tns_trans=True,\n",
    "    lhflx_trans=True,\n",
    "    scaling=False,\n",
    "    interpolate=True,\n",
    "        exp={\"LHFLX\":True}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input distribution measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariate shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take 10 batches\n",
    "X = []\n",
    "y = []\n",
    "for i in range(10):\n",
    "    X_batch_m4k = train_gen_m4k[i][0][:,64:64+2*40+4]\n",
    "    X.append(X_batch_m4k)\n",
    "    y.append([0]*1024)\n",
    "    X_batch_p4k = train_gen_p4k[i][0][:,64:64+2*40+4]\n",
    "    X.append(X_batch_p4k)\n",
    "    y.append([1]*1024)\n",
    "X = np.concatenate(X)\n",
    "y = np.concatenate(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6549426078796386\n",
      "1 0.6513222694396973\n",
      "2 0.6409618377685546\n",
      "3 0.6442202377319336\n",
      "4 0.6725962066650392\n",
      "5 0.6756550598144531\n",
      "6 0.671046781539917\n",
      "7 0.6696936702728271\n",
      "8 0.6532115745544433\n",
      "9 0.631061716079712\n",
      "10 0.6162624549865723\n",
      "11 0.6085258483886719\n",
      "12 0.6117638397216796\n",
      "13 0.6064349079132081\n",
      "14 0.6052550220489502\n",
      "15 0.6028104305267334\n",
      "16 0.5989575862884521\n",
      "17 0.5953474044799805\n",
      "18 0.5930519390106201\n",
      "19 0.5914187240600586\n",
      "20 0.585111494064331\n",
      "21 0.5910529899597168\n",
      "22 0.5865897178649901\n",
      "23 0.5771833419799804\n",
      "24 0.5739281177520752\n",
      "25 0.5718878746032715\n",
      "26 0.5672254943847657\n",
      "27 0.5715892982482911\n",
      "28 0.5686615180969239\n",
      "29 0.5590650463104248\n",
      "30 0.5571450996398926\n",
      "31 0.5626426315307618\n",
      "32 0.5813868618011475\n",
      "33 0.6140272426605224\n",
      "34 0.6540182399749757\n",
      "35 0.6580194759368896\n",
      "36 0.6285828876495361\n",
      "37 0.583179359436035\n",
      "38 0.5876092338562011\n",
      "39 0.560758695602417\n",
      "40 0.7120276927947998\n",
      "41 0.7436960411071778\n",
      "42 0.764973726272583\n",
      "43 0.7857393169403076\n",
      "44 0.7987386131286621\n",
      "45 0.814976167678833\n",
      "46 0.8120562362670898\n",
      "47 0.8083971500396729\n",
      "48 0.8155231475830078\n",
      "49 0.830335636138916\n",
      "50 0.8362400817871094\n",
      "51 0.841662015914917\n",
      "52 0.8370901870727538\n",
      "53 0.8292237949371337\n",
      "54 0.8240860939025878\n",
      "55 0.8183878231048584\n",
      "56 0.8103526496887208\n",
      "57 0.8063996410369874\n",
      "58 0.8022005367279053\n",
      "59 0.795669708251953\n",
      "60 0.7890691566467287\n",
      "61 0.7846273136138916\n",
      "62 0.7785221195220947\n",
      "63 0.7736120414733887\n",
      "64 0.7690666484832764\n",
      "65 0.7646408367156983\n",
      "66 0.7605052947998048\n",
      "67 0.764320468902588\n",
      "68 0.7665667247772217\n",
      "69 0.7715528392791748\n",
      "70 0.7815841484069824\n",
      "71 0.792384786605835\n",
      "72 0.7921758651733399\n",
      "73 0.7925148868560791\n",
      "74 0.7913189315795898\n",
      "75 0.767536563873291\n",
      "76 0.7351927089691161\n",
      "77 0.7130487060546875\n",
      "78 0.7063439750671388\n",
      "79 0.502148323059082\n",
      "80 0.6262562274932861\n",
      "81 0.5\n",
      "82 0.5325524616241455\n",
      "83 0.527020206451416\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators = 50, max_depth = 5,min_samples_leaf = 5)\n",
    "drop_list = []\n",
    "for i in range(84):\n",
    "    score = cross_val_score(model,X[:,i].reshape(-1,1),y,cv=2,scoring='roc_auc')\n",
    "    if (np.mean(score) > 0.8):\n",
    "        drop_list.append(i)\n",
    "    print(i,np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 84)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen_p4k[1][0][:,64:64+2*40+4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64+84+30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CBrainEnv",
   "language": "python",
   "name": "cbrainenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
